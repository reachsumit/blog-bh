<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>Recommender systems - Category - Sumit&#39;s Diary</title>
        <link>https://blog.reachsumit.com/categories/recommender-systems/</link>
        <description>Recommender systems - Category - Sumit&#39;s Diary</description>
        <generator>Hugo -- gohugo.io</generator><language>en</language><managingEditor>hello@reachsumit.com (Sumit Kumar)</managingEditor>
            <webMaster>hello@reachsumit.com (Sumit Kumar)</webMaster><copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><lastBuildDate>Sun, 21 May 2023 00:00:00 &#43;0000</lastBuildDate><atom:link href="https://blog.reachsumit.com/categories/recommender-systems/" rel="self" type="application/rss+xml" /><item>
    <title>Tuning Large Language Models for Recommendation Tasks</title>
    <link>https://blog.reachsumit.com/posts/2023/05/tuning-llm-for-recsys/</link>
    <pubDate>Sun, 21 May 2023 00:00:00 &#43;0000</pubDate><author>
        <name>Sumit Kumar</name>
    </author><guid>https://blog.reachsumit.com/posts/2023/05/tuning-llm-for-recsys/</guid>
    <description><![CDATA[<div class="featured-image">
                <img src="/posts/2023/05/tuning-llm-for-recsys/featured-image-preview.webp" referrerpolicy="no-referrer">
            </div>Instruction-tuning methods enable open-source Large Language Models (LLMs) usage for building highly effective recommender systems on private data. This article highlights the latest research work on this paradigm of using LLMs for recommendation tasks.]]></description>
</item><item>
    <title>ChatGPT-based Recommender Systems</title>
    <link>https://blog.reachsumit.com/posts/2023/05/chatgpt-for-recsys/</link>
    <pubDate>Mon, 15 May 2023 00:00:00 &#43;0000</pubDate><author>
        <name>Sumit Kumar</name>
    </author><guid>https://blog.reachsumit.com/posts/2023/05/chatgpt-for-recsys/</guid>
    <description><![CDATA[<div class="featured-image">
                <img src="/posts/2023/05/chatgpt-for-recsys/featured-image-preview.webp" referrerpolicy="no-referrer">
            </div><p>With its outstanding performance, ChatGPT has become a hot topic of discussion in the NLP community and beyond. This article delves into recent efforts to harness the power of ChatGPT for recommendation tasks.</p>]]></description>
</item><item>
    <title>Mixture-of-Experts based Recommender Systems</title>
    <link>https://blog.reachsumit.com/posts/2023/04/moe-for-recsys/</link>
    <pubDate>Sun, 23 Apr 2023 00:00:00 &#43;0000</pubDate><author>
        <name>Sumit Kumar</name>
    </author><guid>https://blog.reachsumit.com/posts/2023/04/moe-for-recsys/</guid>
    <description><![CDATA[<div class="featured-image">
                <img src="/posts/2023/04/moe-for-recsys/featured-image-preview.webp" referrerpolicy="no-referrer">
            </div>The Mixture-of-Experts (MoE) is a classical ensemble learning technique originally proposed by Jacobs et. al1 in 1991. MoEs have the capability to substantially scale up the model capacity and only introduce small computation overhead. This ability combined with recent innovations in the deep learning domain has led to the wide-scale adoption of MoEs in healthcare, finance, pattern recognition, etc. They have been successfully utilized in large-scale applications such as Large Language Modeling (LLM), Machine Translation, and Recommendations.]]></description>
</item><item>
    <title>Diffusion Modeling based Recommender Systems</title>
    <link>https://blog.reachsumit.com/posts/2023/04/diffusion-for-recsys/</link>
    <pubDate>Mon, 17 Apr 2023 00:00:00 &#43;0000</pubDate><author>
        <name>Sumit Kumar</name>
    </author><guid>https://blog.reachsumit.com/posts/2023/04/diffusion-for-recsys/</guid>
    <description><![CDATA[<div class="featured-image">
                <img src="/posts/2023/04/diffusion-for-recsys/featured-image-preview.webp" referrerpolicy="no-referrer">
            </div>Diffusion Models have exhibited state-of-the-art results in image and audio synthesis domains. A recent line of research has started to adopt Diffusion for recommender systems. This article introduces Diffusion and its relevance to the recommendations domain and also highlights some of the most recent proposals on this novel theme.]]></description>
</item><item>
    <title>Zero and Few Shot Recommender Systems based on Large Language Models</title>
    <link>https://blog.reachsumit.com/posts/2023/04/llm-for-recsys/</link>
    <pubDate>Mon, 10 Apr 2023 00:00:00 &#43;0000</pubDate><author>
        <name>Sumit Kumar</name>
    </author><guid>https://blog.reachsumit.com/posts/2023/04/llm-for-recsys/</guid>
    <description><![CDATA[<div class="featured-image">
                <img src="/posts/2023/04/llm-for-recsys/featured-image-preview.webp" referrerpolicy="no-referrer">
            </div><p>Recent developments in Large Language Models (LLMs) have brought a significant paradigm shift in Natural Language Processing (NLP) domain. These pretrained language models encode an extensive amount of world knowledge, and they can be applied to a multitude of downstream NLP applications with zero or just a handful of demonstrations.</p>
<p>While existing recommender systems mainly focus on behavior data, large language models encode extensive world knowledge mined from large-scale web corpora. Hence these LLMs store knowledge that can complement the behavior data. For example, an LLM-based system, like ChatGPT, can easily recommend buying turkey on Thanksgiving day, in a zero-shot manner, even without having click behavior data related to turkeys or Thanksgiving.</p>
<p>Many researchers have recently proposed different approaches to building recommender systems using LLMs. These methods convert different recommendation tasks into either language understanding or language generation templates. This article highlights the prominent work done on this theme.</p>]]></description>
</item><item>
    <title>Twitter&#39;s For You Recommendation Algorithm</title>
    <link>https://blog.reachsumit.com/posts/2023/04/the-twitter-ml-algo/</link>
    <pubDate>Tue, 04 Apr 2023 00:00:00 &#43;0000</pubDate><author>
        <name>Sumit Kumar</name>
    </author><guid>https://blog.reachsumit.com/posts/2023/04/the-twitter-ml-algo/</guid>
    <description><![CDATA[<div class="featured-image">
                <img src="/posts/2023/04/the-twitter-ml-algo/featured-image-preview.webp" referrerpolicy="no-referrer">
            </div>Twitter has open-sourced a majority of its recommendation algorithm. It offers an exciting opportunity for researchers, industry practitioners, and RecSys enthusiasts to take a close look at how Twitter computes the recommended feed for the For You page. This article described Twitter&rsquo;s end-to-end recommender system along with relevant literature and code references.]]></description>
</item><item>
    <title>Next Gen Recommender Systems: Real-time reranking on mobile devices</title>
    <link>https://blog.reachsumit.com/posts/2023/03/reranking-on-edge/</link>
    <pubDate>Thu, 09 Mar 2023 00:00:00 &#43;0000</pubDate><author>
        <name>Sumit Kumar</name>
    </author><guid>https://blog.reachsumit.com/posts/2023/03/reranking-on-edge/</guid>
    <description><![CDATA[<div class="featured-image">
                <img src="/posts/2023/03/reranking-on-edge/featured-image-preview.webp" referrerpolicy="no-referrer">
            </div>A traditional cloud-to-edge recommender system can&rsquo;t respond to user engagement and interests in real time. This article introduces on-device inference and on-device learning paradigms that can capture rich user behavior and respond to users&rsquo; changing interests in real time. The article also goes through system design choices and implementation details of different industrial applications that have served recommendations to billions of users, such as Kuaishou&rsquo;s Short Video Recommendation on Mobile Devices, and Taobao&rsquo;s (Alibaba) on-device recommender systems.]]></description>
</item><item>
    <title>Collaborative Filtering based Recommender Systems for Implicit Feedback Data</title>
    <link>https://blog.reachsumit.com/posts/2022/09/explicit-implicit-cf/</link>
    <pubDate>Sun, 25 Sep 2022 00:00:00 &#43;0000</pubDate><author>
        <name>Sumit Kumar</name>
    </author><guid>https://blog.reachsumit.com/posts/2022/09/explicit-implicit-cf/</guid>
    <description><![CDATA[<div class="featured-image">
                <img src="/posts/2022/09/explicit-implicit-cf/featured-image-preview.webp" referrerpolicy="no-referrer">
            </div>This article explains what explicit and implicit feedback data means for recommender systems. We discuss their characteristics and peculiarities concerning collaborative filtering based algorithms. Then we go over one of the most popular collaborative filtering algorithms for implicit data and implement it in Python with an example dataset.]]></description>
</item></channel>
</rss>
