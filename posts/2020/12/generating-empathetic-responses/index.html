<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="robots" content="noodp" />
    <title>Towards Empathetic Dialogue Systems - Sumit&#39;s Diary</title><meta name="Description" content="Recognizing feelings in the conversation partner and replying empathetically is a trivial skill for humans. But how can we infuse empathy into responses generated by a conversational dialogue agent or any of the text generation algorithm in Natural Language Processing? In this article, I will describe what empathy means through the lens of various academic disciplines and then do an in-depth review of the prior and current state-of-the-art NLU systems that can simulate empathy."><meta property="og:title" content="Towards Empathetic Dialogue Systems" />
<meta property="og:description" content="Recognizing feelings in the conversation partner and replying empathetically is a trivial skill for humans. But how can we infuse empathy into responses generated by a conversational dialogue agent or any of the text generation algorithm in Natural Language Processing? In this article, I will describe what empathy means through the lens of various academic disciplines and then do an in-depth review of the prior and current state-of-the-art NLU systems that can simulate empathy." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://blog.reachsumit.com/posts/2020/12/generating-empathetic-responses/" /><meta property="og:image" content="https://blog.reachsumit.com/posts/2020/12/generating-empathetic-responses/featured-image-preview.webp"/><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2020-12-07T00:00:00+00:00" />
<meta property="article:modified_time" content="2020-12-07T00:00:00+00:00" />

<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://blog.reachsumit.com/posts/2020/12/generating-empathetic-responses/featured-image-preview.webp"/>
<meta name="twitter:title" content="Towards Empathetic Dialogue Systems"/>
<meta name="twitter:description" content="Recognizing feelings in the conversation partner and replying empathetically is a trivial skill for humans. But how can we infuse empathy into responses generated by a conversational dialogue agent or any of the text generation algorithm in Natural Language Processing? In this article, I will describe what empathy means through the lens of various academic disciplines and then do an in-depth review of the prior and current state-of-the-art NLU systems that can simulate empathy."/>
<meta name="application-name" content="Sumit&#39;s Diary">
<meta name="apple-mobile-web-app-title" content="Sumit&#39;s Diary">

<meta name="theme-color" content="#f8f8f8"><meta name="msapplication-TileColor" content="#da532c"><link rel="icon" href="/img/avatar/favicon.ico"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="canonical" href="https://blog.reachsumit.com/posts/2020/12/generating-empathetic-responses/" /><link rel="prev" href="https://blog.reachsumit.com/posts/2020/10/leetcode-sliding-window/" /><link rel="next" href="https://blog.reachsumit.com/posts/2022/06/sql-nosql-newsql/" /><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/normalize.css@8.0.1/normalize.min.css"><link rel="stylesheet" href="/css/color.css"><link rel="stylesheet" href="/css/style.min.css"><link rel="preload" as="style" onload="this.onload=null;this.rel='stylesheet'" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css">
        <noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css"></noscript><link rel="preload" as="style" onload="this.onload=null;this.rel='stylesheet'" href="https://cdn.jsdelivr.net/npm/animate.css@4.1.1/animate.min.css">
        <noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@4.1.1/animate.min.css"></noscript><script type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "BlogPosting",
        "headline": "Towards Empathetic Dialogue Systems",
        "inLanguage": "en",
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "https:\/\/blog.reachsumit.com\/posts\/2020\/12\/generating-empathetic-responses\/"
        },"image": ["https:\/\/blog.reachsumit.com\/images\/Apple-Devices-Preview.png"],"genre": "posts","keywords": "dialogue systems, literature review","wordcount":  4261 ,
        "url": "https:\/\/blog.reachsumit.com\/posts\/2020\/12\/generating-empathetic-responses\/","datePublished": "2020-12-07T00:00:00+00:00","dateModified": "2020-12-07T00:00:00+00:00","license": "This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.","publisher": {
            "@type": "Organization",
            "name": "xxxx","logo": "https:\/\/blog.reachsumit.com\/images\/avatar.png"},"author": {
                "@type": "Person",
                "name": "Sumit Kumar"
            },"description": "Recognizing feelings in the conversation partner and replying empathetically is a trivial skill for humans. But how can we infuse empathy into responses generated by a conversational dialogue agent or any of the text generation algorithm in Natural Language Processing? In this article, I will describe what empathy means through the lens of various academic disciplines and then do an in-depth review of the prior and current state-of-the-art NLU systems that can simulate empathy."
    }
    </script><script src="//instant.page/5.1.1" defer type="module" integrity="sha384-MWfCL6g1OTGsbSwfuMHc8+8J2u71/LA8dzlIN3ycajckxuZZmF+DNjdm7O6H3PSq"></script>
</head>

<body header-desktop="fixed" header-mobile="auto"><script type="text/javascript">
        function setTheme(theme) {document.body.setAttribute('theme', theme); document.documentElement.style.setProperty('color-scheme', theme === 'light' ? 'light' : 'dark');}
        function saveTheme(theme) {window.localStorage && localStorage.setItem('theme', theme);}
        function getMeta(metaName) {const metas = document.getElementsByTagName('meta'); for (let i = 0; i < metas.length; i++) if (metas[i].getAttribute('name') === metaName) return metas[i]; return '';}
        if (window.localStorage && localStorage.getItem('theme')) {let theme = localStorage.getItem('theme');theme === 'light' || theme === 'dark' || theme === 'black' ? setTheme(theme) : (window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches ? setTheme('dark') : setTheme('light')); } else { if ('light' === 'light' || 'light' === 'dark' || 'light' === 'black') setTheme('light'), saveTheme('light'); else saveTheme('auto'), window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches ? setTheme('dark') : setTheme('light');}
        let metaColors = {'light': '#f8f8f8','dark': '#252627','black': '#000000'}
        getMeta('theme-color').content = metaColors[document.body.getAttribute('theme')];
    </script>
    <div id="back-to-top"></div>
    <div id="mask"></div><div class="wrapper"><header class="desktop" id="header-desktop">
    <div class="header-wrapper">
        <div class="header-title">
            <a href="/" title="Sumit&#39;s Diary"><span id="desktop-header-typeit" class="typeit"></span></a>
        </div>
        <div class="menu">
            <div class="menu-inner"><a class="menu-item" href="/posts/"> Posts </a><a class="menu-item" href="/tags/"> Tags </a><a class="menu-item" href="/categories/"> Categories </a><a class="menu-item" href="/about/"> About </a><span class="menu-item delimiter"></span><span class="menu-item search" id="search-desktop">
                        <input type="text" placeholder="Search this blog" id="search-input-desktop">
                        <a href="#" class="search-button search-toggle" id="search-toggle-desktop" title="Search">
                            <i class="fas fa-search fa-fw"></i>
                        </a>
                        <a href="#" class="search-button search-clear" id="search-clear-desktop" title="Clear">
                            <i class="fas fa-times-circle fa-fw"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-desktop">
                            <i class="fas fa-spinner fa-fw fa-spin"></i>
                        </span>
                    </span><a href="#" class="menu-item theme-select" title="Switch Theme">
                    <i class="fas fa-adjust fa-fw"></i>
                    <select class="color-theme-select" id="theme-select-desktop" title="Switch Theme">
                        <option value="light">Light</option>
                        <option value="dark">Dark</option>
                        <option value="black">Black</option>
                        <option value="auto">Auto</option>
                    </select>
                </a></div>
        </div>
    </div>
</header><header class="mobile" id="header-mobile">
    <div class="header-container">
        <div class="header-wrapper">
            <div class="header-title">
                <a href="/" title="Sumit&#39;s Diary"><span id="mobile-header-typeit" class="typeit"></span></a>
            </div>
            <div class="menu-toggle" id="menu-toggle-mobile">
                <span></span><span></span><span></span>
            </div>
        </div>
        <div class="menu" id="menu-mobile"><div class="search-wrapper">
                    <div class="search mobile" id="search-mobile">
                        <input type="text" placeholder="Search this blog" id="search-input-mobile">
                        <a href="#" class="search-button search-toggle" id="search-toggle-mobile" title="Search">
                            <i class="fas fa-search fa-fw"></i>
                        </a>
                        <a href="#" class="search-button search-clear" id="search-clear-mobile" title="Clear">
                            <i class="fas fa-times-circle fa-fw"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-mobile">
                            <i class="fas fa-spinner fa-fw fa-spin"></i>
                        </span>
                    </div>
                    <a href="#" class="search-cancel" id="search-cancel-mobile">
                        Cancel
                    </a>
                </div><a class="menu-item" href="/posts/" title="">Posts</a><a class="menu-item" href="/tags/" title="">Tags</a><a class="menu-item" href="/categories/" title="">Categories</a><a class="menu-item" href="/about/" title="">About</a><a href="#" class="menu-item theme-select" title="Switch Theme">
                <i class="fas fa-adjust fa-fw"></i>
                <select class="color-theme-select" id="theme-select-mobile" title="Switch Theme">
                    <option value="light">Light</option>
                    <option value="dark">Dark</option>
                    <option value="black">Black</option>
                    <option value="auto">Auto</option>
                </select>
            </a></div>
    </div>
</header>
<div class="search-dropdown desktop">
    <div id="search-dropdown-desktop"></div>
</div>
<div class="search-dropdown mobile">
    <div id="search-dropdown-mobile"></div>
</div>
<main class="main">
            <div class="container"><div class="toc" id="toc-auto">
        <h2 class="toc-title">Contents</h2>
        <div class="toc-content" id="toc-content-auto"><nav id="TableOfContents">
  <ul>
    <li><a href="#empathy-and-its-linguistic-origin">Empathy and its Linguistic Origin</a></li>
    <li><a href="#the-importance-of-empathy">The Importance of Empathy</a></li>
    <li><a href="#what-does-empathy-mean-for-nlp">What does Empathy Mean for NLP?</a></li>
    <li><a href="#nlp-research-on-empathy">NLP Research on Empathy</a>
      <ul>
        <li><a href="#early-works">Early Works</a>
          <ul>
            <li><a href="#zara-the-supergirl">Zara The Supergirl</a></li>
            <li><a href="#nora-the-empathetic-psychologist">Nora the Empathetic Psychologist</a></li>
            <li><a href="#real-time-speech-emotion-and-sentiment-recognition-for-interactive-dialogue-systems">Real-Time Speech Emotion and Sentiment Recognition for Interactive Dialogue Systems</a></li>
            <li><a href="#generating-emotionally-flexible-responses">Generating Emotionally Flexible Responses</a></li>
            <li><a href="#using-natural-labels-to-generate-an-emotional-response">Using &ldquo;natural labels&rdquo; to generate an emotional response</a></li>
            <li><a href="#using-gan-to-generate-emotionally-diverse-responses">Using GAN to generate emotionally diverse responses</a></li>
            <li><a href="#a-dual-decoder-framework-to-generate-a-response-with-given-sentiment">A Dual-decoder framework to generate a response with given sentiment</a></li>
            <li><a href="#using-reinforcement-learning-to-reward-future-emotional-states">Using Reinforcement Learning to reward future emotional states</a></li>
            <li><a href="#formalizing-empathy-generation-a-new-dataset-from-facebook-ai-research">Formalizing Empathy Generation: A new dataset from Facebook AI Research</a></li>
            <li><a href="#maximizing-positive-arousal">Maximizing Positive Arousal</a></li>
          </ul>
        </li>
        <li><a href="#current-state-of-the-art-research-on-empathetic-response-generation">Current State-of-the-Art Research on Empathetic Response Generation</a>
          <ul>
            <li><a href="#moel-mixture-of-empathetic-listeners">MoEL: Mixture of Empathetic Listeners</a></li>
            <li><a href="#mime-mimicking-emotions-for-empathetic-response-generation">MIME: MIMicking Emotions for Empathetic Response Generation</a></li>
          </ul>
        </li>
      </ul>
    </li>
    <li><a href="#conclusion">Conclusion</a></li>
    <li><a href="#references">References</a></li>
  </ul>
</nav></div>
    </div><script>document.getElementsByTagName("main")[0].setAttribute("pageStyle", "normal")</script><script>document.getElementsByTagName("main")[0].setAttribute("autoTOC", "true")</script><article class="page single"><h1 class="single-title animate__animated animate__flipInX">Towards Empathetic Dialogue Systems</h1><div class="post-meta">
            <div class="post-meta-line">
                <span class="post-author"><i class="author fas fa-user-circle fa-fw"></i><a href="https://reachsumit.com" title="Author" target="_blank" rel="noopener noreferrer author" class="author">Sumit Kumar</a>
                </span>&nbsp;<span class="post-category">included in </span>&nbsp;<span class="post-category">category <a href="/categories/nlp/"><i class="far fa-folder fa-fw"></i>NLP</a></span></div>
            <div class="post-meta-line"><i class="far fa-calendar-alt fa-fw"></i>&nbsp;<time datetime="2020-12-07">2020-12-07</time>&nbsp;<i class="far fa-edit fa-fw"></i>&nbsp;<time datetime="2020-12-07">2020-12-07</time>&nbsp;<i class="fas fa-pencil-alt fa-fw"></i>&nbsp;4261 words&nbsp;
                <i class="far fa-clock fa-fw"></i>&nbsp;21 minutes&nbsp;</div>
        </div><div class="featured-image"><img
        
        loading="eager"
        src="/posts/2020/12/generating-empathetic-responses/featured-image.webp"
        srcset="/posts/2020/12/generating-empathetic-responses/featured-image.webp, /posts/2020/12/generating-empathetic-responses/featured-image.webp 1.5x, /posts/2020/12/generating-empathetic-responses/featured-image.webp 2x"
        sizes="auto"
        alt="/posts/2020/12/generating-empathetic-responses/featured-image.webp"
        title="Recognizing feelings in the conversation partner and replying empathetically is a trivial skill for humans. But how can we infuse empathy into responses generated by a conversational dialogue agent or any of the text generation algorithm in Natural Language Processing? In this article, I will describe what empathy means through the lens of various academic disciplines and then do an in-depth review of the prior and current state-of-the-art NLU systems that can simulate empathy." height="600" width="1200"></div><div class="details toc" id="toc-static"  kept="">
                <div class="details-summary toc-title">
                    <span>Contents</span>
                    <span><i class="details-icon fas fa-angle-right"></i></span>
                </div>
                <div class="details-content toc-content" id="toc-content-static"><nav id="TableOfContents">
  <ul>
    <li><a href="#empathy-and-its-linguistic-origin">Empathy and its Linguistic Origin</a></li>
    <li><a href="#the-importance-of-empathy">The Importance of Empathy</a></li>
    <li><a href="#what-does-empathy-mean-for-nlp">What does Empathy Mean for NLP?</a></li>
    <li><a href="#nlp-research-on-empathy">NLP Research on Empathy</a>
      <ul>
        <li><a href="#early-works">Early Works</a>
          <ul>
            <li><a href="#zara-the-supergirl">Zara The Supergirl</a></li>
            <li><a href="#nora-the-empathetic-psychologist">Nora the Empathetic Psychologist</a></li>
            <li><a href="#real-time-speech-emotion-and-sentiment-recognition-for-interactive-dialogue-systems">Real-Time Speech Emotion and Sentiment Recognition for Interactive Dialogue Systems</a></li>
            <li><a href="#generating-emotionally-flexible-responses">Generating Emotionally Flexible Responses</a></li>
            <li><a href="#using-natural-labels-to-generate-an-emotional-response">Using &ldquo;natural labels&rdquo; to generate an emotional response</a></li>
            <li><a href="#using-gan-to-generate-emotionally-diverse-responses">Using GAN to generate emotionally diverse responses</a></li>
            <li><a href="#a-dual-decoder-framework-to-generate-a-response-with-given-sentiment">A Dual-decoder framework to generate a response with given sentiment</a></li>
            <li><a href="#using-reinforcement-learning-to-reward-future-emotional-states">Using Reinforcement Learning to reward future emotional states</a></li>
            <li><a href="#formalizing-empathy-generation-a-new-dataset-from-facebook-ai-research">Formalizing Empathy Generation: A new dataset from Facebook AI Research</a></li>
            <li><a href="#maximizing-positive-arousal">Maximizing Positive Arousal</a></li>
          </ul>
        </li>
        <li><a href="#current-state-of-the-art-research-on-empathetic-response-generation">Current State-of-the-Art Research on Empathetic Response Generation</a>
          <ul>
            <li><a href="#moel-mixture-of-empathetic-listeners">MoEL: Mixture of Empathetic Listeners</a></li>
            <li><a href="#mime-mimicking-emotions-for-empathetic-response-generation">MIME: MIMicking Emotions for Empathetic Response Generation</a></li>
          </ul>
        </li>
      </ul>
    </li>
    <li><a href="#conclusion">Conclusion</a></li>
    <li><a href="#references">References</a></li>
  </ul>
</nav></div>
            </div><div class="content" id="content"><p>Recognizing feelings in the conversation partner and replying empathetically is a trivial skill for humans. But how can we infuse empathy into responses generated by a conversational dialogue agent or any of the text generation algorithm in Natural Language Processing? In this article, I will describe what empathy means through the lens of various academic disciplines and then do an in-depth review of the prior and current state-of-the-art NLU systems that can simulate empathy.</p>
<h2 id="empathy-and-its-linguistic-origin" class="headerLink">
    <a href="#empathy-and-its-linguistic-origin" class="header-mark"></a>Empathy and its Linguistic Origin</h2><p>The word empathy has a rather interesting linguistic history. In 1909, this word was first introduced in English by psychologist Edward Titchener as a translation of the German word Einfühlung, which means &ldquo;feeling into&rdquo; or &ldquo;in-feeling&rdquo;. The German word itself was adapted from the Ancient Greek word &ldquo;ἐμπάθεια&rdquo; or &ldquo;empátheia&rdquo; meaning &ldquo;in passion&rdquo; (from Greek &rsquo;en pathos&rsquo;). Einfühlung first appeared in Robert Vischer’s 1873 Ph.D. dissertation, where Vischer used it to describe the human ability to enter into a piece of art or literature and feel the emotions of its <em><cite>creator<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup></cite></em>. Even though in modern Greek, the word empátheia has an opposite meaning, a strong negative feeling or prejudice against someone; the English word empathy does not carry those negative connotations.</p>
<p>The modern-day usage of the word empathy pertains to the range of psychological capacities that play a central role in establishing humans as social and moral animals. It enables us to “put ourselves into someone else’s shoes”. Before the introduction of &ldquo;empathy&rdquo; in the English language, the word sympathy was used to describe a related phenomenon of understanding others&rsquo; <em><cite>feelings<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup></cite></em>. However, empathy is used as a broader concept to address a phenomenon of not just understanding someone&rsquo;s emotions and but also viscerally feeling them.</p>
<h2 id="the-importance-of-empathy" class="headerLink">
    <a href="#the-importance-of-empathy" class="header-mark"></a>The Importance of Empathy</h2><p>Theodor Lipps was a German philosopher who posited the theory that empathy should be understood as the primary epistemic means for gaining knowledge of other minds. While this theory has been a topic of contentious debate in the field of philosophy, the study and scientific exploration of empathy as a social science phenomenon have been less critical. There are two major focus areas involving empathy in social science. The first one treats empathy as a cognitive phenomenon and attempts to measure the accuracy of one&rsquo;s abilities to recognize others&rsquo; personality, attitude, and moral traits. It concerns with the factors that affect empathy. For example, do age, gender, upbringing, family history, relationships impact empathy in a <em><cite>person<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup></cite></em>? The second focus area treats empathy as a rather emotional phenomenon and finds means to measure empathy and other perceptual factors that trigger empathetic responses. The interdisciplinary field of neuroscience, on the other hand, researches into the processes that neurologically enable a person to feel what another is <em><cite>feeling<sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup></cite></em>.</p>
<p>Empathy enhances social <em><cite>functioning<sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup></cite></em>. The ability to understand and share feelings of other people around us enables us to also understand their present and future mental state and actions. It can even encourage prosocial behaviors by motivating humans to act altruistically towards kin, mates and, <em><cite>allies<sup id="fnref:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup> <sup id="fnref:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup></cite></em>. In their book &ldquo;Empathy Reconsidered: New Directions in Psychotherapy&rdquo;, Arthur Bohart and Leslie Greenberg, explored the role that empathy plays in <em><cite>psychotherapy<sup id="fnref:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup></cite></em>. Their work propounded that all forms of psychotherapy are effective as a result of empathetic processes, and made the case for ensuring that psychotherapists are empathetically engaging with their clients. Other researches have shown the positive impact of empathy in mental healthcare, nursing, and even primary care. Researchers Stewart Mercer and William Reynolds highlighted the importance of empathy in the quality of primary care, in their paper titled <em><cite>&ldquo;Empathy and quality of care&rdquo;<sup id="fnref:9"><a href="#fn:9" class="footnote-ref" role="doc-noteref">9</a></sup></cite></em>. There are a substantial number of similar studies that show a wide range of applications of empathy in healthcare.</p>
<h2 id="what-does-empathy-mean-for-nlp" class="headerLink">
    <a href="#what-does-empathy-mean-for-nlp" class="header-mark"></a>What does Empathy Mean for NLP?</h2><p>Natural Language Processing has proved to be an exceedingly viable tool to bridge the conversational gap between humans and machines. Various industries are now using conversational AI assistants (or chatbots) to improve their customer service. Not only these artificial conversational agents can understand users&rsquo; intent and respond to them, but they are also increasingly becoming capable of understanding users&rsquo; emotions. NLP researchers are looking into ways to infuse the human trait of empathy into conversational agents to create more empathetic end-user experience.</p>
<p>As an example, consider the following two scenarios where an Amazon customer reaches out to a customer service bot to complain about their order not being delivered on time. The choice of words used by the customer in the two scenarios convey differently charged emotions. Compared to scenario 1, the customer sounds more distressed in scenario 2. An optimal response from the bot in the second scenario should not feel like an off-the-shelf template response. An ideal response may start with first acknowledging the understanding of the customer&rsquo;s frustration and displaying empathy to subdue their negatively charged emotions. A compassionate choice of words in the response can not only alleviate some of the customer annoyance, but it may also help in better customer retention in the long run.</p>
<div id="id-1"><img src="/img/posts/generating-empathetic-responses/two_scenarios.png" alt="Two Helping Scenarios"></div>
<h2 id="nlp-research-on-empathy" class="headerLink">
    <a href="#nlp-research-on-empathy" class="header-mark"></a>NLP Research on Empathy</h2><h3 id="early-works" class="headerLink">
    <a href="#early-works" class="header-mark"></a>Early Works</h3><p>The topics of identifying and generating empathy in natural langue processing haven&rsquo;t seen as explosive research growth and application as topics like sentiment analysis. Perhaps the earliest work in identifying empathy in text data was done by <em><cite>Xiao et al., 2012<sup id="fnref:10"><a href="#fn:10" class="footnote-ref" role="doc-noteref">10</a></sup></cite></em>, when they developed an N-gram language model-based maximum likelihood strategy to classify empathetic vs non-empathetic utterances from a dataset of clinical trial studies on substance use by college students. In 2015, <em><cite>Gibson et al.<sup id="fnref:11"><a href="#fn:11" class="footnote-ref" role="doc-noteref">11</a></sup></cite></em> proposed computation of features based upon psycholinguistic norms, and in 2017, <em><cite>Khanpour et al.<sup id="fnref:12"><a href="#fn:12" class="footnote-ref" role="doc-noteref">12</a></sup></cite></em> used a simple combination of Convolutional Neural Networks (CNN) and Long Short Term Memory (LSTM) networks to identify empathetic messages in online health communities. It&rsquo;s worth highlighting that most of these researches used datasets that weren&rsquo;t publicly available to the NLP community.</p>
<p>In 2018, <em><cite>Buechel et al.<sup id="fnref:13"><a href="#fn:13" class="footnote-ref" role="doc-noteref">13</a></sup></cite></em> published their research which they claimed to be the first gold-standard for empathy prediction. Their paper looked at a more nuanced form of empathy that was based on psychology and included empathic concern, and personal distress. Also, the empathy ratings in their dataset were provided by writers instead of other annotators. They used Ridge regression, simple feed-forward neural nets, and CNN for their empathy prediction tasks on newswire articles. In somewhat related research, <em><cite>Perez-Rosas et al.<sup id="fnref:14"><a href="#fn:14" class="footnote-ref" role="doc-noteref">14</a></sup></cite></em> looked into behavioral counseling and proposed a quantitative approach to understand the dynamics of counseling interactions and counselor empathy during motivational interviewing. They first identified linguistic and acoustic empathy markers and used those along with raw features to train classifiers that were able to predict counselor empathy.</p>
<p>Some of the other prominent researches are listed below:</p>
<h4 id="zara-the-supergirl" class="headerLink">
    <a href="#zara-the-supergirl" class="header-mark"></a>Zara The Supergirl</h4><p>Zara was an Empathetic Personality Recognition System created by  <em><cite>Fung, Dey et al.<sup id="fnref:15"><a href="#fn:15" class="footnote-ref" role="doc-noteref">15</a></sup></cite></em>.  Their research showed an interactive dialogue system that did sentiment analysis, emotion recognition, facial and speech recognition to extract user emotions in a human-robot conversational setup. They deployed their virtual robot as a webapp where users can interact with an animated cartoon character, Zara. You can watch their <a href="https://www.youtube.com/watch?v=8UNpeETggpU" target="_blank" rel="noopener noreferrer">demo video on YouTube</a> and also interact with their <a href="https://zara.emos.ai/zaraChat" target="_blank" rel="noopener noreferrer">online webapp</a>.</p>
<div id="id-2"><img src="/img/posts/generating-empathetic-responses/zara_youtube_2.png" alt="Zara YouTube Dem"></div>
<p>Zara assesses a user&rsquo;s personality by asking a series of questions, along with the follow-up inquiries, on different topics like the user&rsquo;s childhood memory, last vacation, challenges at work, etc. It uses OpenSmile and Kaldi to perform emotion recognition from user audio, keyword matches from a pool of positive and negative emotion lexicons to perform sentiment analysis, and then uses these results to calculate the scores in four personality dimensions -  extroversion, intuitive, judging, perceiving.</p>
<h4 id="nora-the-empathetic-psychologist" class="headerLink">
    <a href="#nora-the-empathetic-psychologist" class="header-mark"></a>Nora the Empathetic Psychologist</h4><p>Similar to Zara, researchers <em><cite>Winata, Kampman et al.<sup id="fnref:16"><a href="#fn:16" class="footnote-ref" role="doc-noteref">16</a></sup></cite></em> crated a virtual psychologist, an empathetic dialogue system named Nora, that could mimic a conversation with a psychologist. Nora employed a natural language understanding (NLU) module to classify user intent and slots, a dialogue management module to evaluate NLU output and manage dialog turns, and a language generation module to respond to the user. A simple CNN was used to detect stress, personality, sentiment, and six different emotions from audio.</p>
<div id="id-3"><img src="/img/posts/generating-empathetic-responses/nora_demo.PNG" alt="Nora Demo"></div>
<h4 id="real-time-speech-emotion-and-sentiment-recognition-for-interactive-dialogue-systems" class="headerLink">
    <a href="#real-time-speech-emotion-and-sentiment-recognition-for-interactive-dialogue-systems" class="header-mark"></a>Real-Time Speech Emotion and Sentiment Recognition for Interactive Dialogue Systems</h4><p><em><cite>Bertero, Siddique et al.<sup id="fnref:17"><a href="#fn:17" class="footnote-ref" role="doc-noteref">17</a></sup></cite></em> also used a CNN-based approach to recognize emotion and sentiment from raw audio data in real-time to enable an empathetic conversational dialogue system. They used the Kaldi speech recognition toolkit to train deep neural network hidden Markov models (DNN-HMMs) that used the raw audio together with encode-decode parallel audio and outperformed the SVM baseline. Their work avoided any feature engineering to enable real-time speech processing.</p>
<h4 id="generating-emotionally-flexible-responses" class="headerLink">
    <a href="#generating-emotionally-flexible-responses" class="header-mark"></a>Generating Emotionally Flexible Responses</h4><p>One of the first studies into large-scale empathetic response generation was done by <em><cite>Zhou, Huang et al.<sup id="fnref:18"><a href="#fn:18" class="footnote-ref" role="doc-noteref">18</a></sup></cite></em> in their Emotional Chatting Machine (ECM) proposal. They used a sequence-to-sequence model with GRU units to generate a response from a given input (post). While prior art, such as <em><cite>Ghosh et al. 2017<sup id="fnref:19"><a href="#fn:19" class="footnote-ref" role="doc-noteref">19</a></sup></cite></em>, used to mimic the emotion inferred from the input, the authors of this paper put forth the idea that a way to give the chatbot a personality is to let it choose an emotion category for the response. However, there could be multiple emotion categories, such as sympathy, anger, happiness, etc., that could be infused in the response under different scenarios. So their work focused on enabling flexible emotional interaction between a post and a response.</p>
<div id="id-4"><img src="/img/posts/generating-empathetic-responses/ecm.png" width="1030" alt="ECM Architecture]"></div>
<p>They learn a vector representation for each category of emotion and feed this vector, along with word embeddings of the input and context output from the encoder, to the decoder. Some of the earlier psychological studies show that the emotional responses are dynamic and short-lived, so the authors create an internal memory containing a state for each of the emotional categories and at each step, the emotional state decays by a certain amount indicating that some of the emotion has been expressed. And finally, the authors provision an external memory at the decoder, which assigns generation probability for the output word to be either an emotional word (such as lovely, awesome, etc.) or a generic word (such as a person, day, etc.).</p>
<h4 id="using-natural-labels-to-generate-an-emotional-response" class="headerLink">
    <a href="#using-natural-labels-to-generate-an-emotional-response" class="header-mark"></a>Using &ldquo;natural labels&rdquo; to generate an emotional response</h4><p>Lack of large-scale labeled training data is a major challenge towards building empathetic natural language processing agents. <em><cite>Zhou and Wang, 2018<sup id="fnref:20"><a href="#fn:20" class="footnote-ref" role="doc-noteref">20</a></sup></cite></em> took an interesting approach to collect a large-scale emotional text dataset. They gathered Twitter conversations that included emojis in the response and assumed the emoji to be the natural label conveying the underlying emotions of the sentence. If a response contains more than one emoji, then the one with the highest occurrence (in response or in the corpus) is considered to be the label. They then trained a few variations of conditional variational autoencoder (CVAE) to automatically generate the emotional responses.</p>
<h4 id="using-gan-to-generate-emotionally-diverse-responses" class="headerLink">
    <a href="#using-gan-to-generate-emotionally-diverse-responses" class="header-mark"></a>Using GAN to generate emotionally diverse responses</h4><p>Generative Adversarial Nets (GANs) often suffer from problems like poor quality, lack of diversity, and mode collapse when used for text generation. But <em><cite>Wang and Wan, 2018<sup id="fnref:21"><a href="#fn:21" class="footnote-ref" role="doc-noteref">21</a></sup></cite></em> proposed a novel GAN framework, named SentiGAN, which could generate a variety of high-quality texts of different sentiment labels. For example, assuming that the goal is to generate texts with k types of sentiments(i.e. k sentiment labels), their architecture proposed training k generators simultaneously without supervision. Using a new penalty based objective each generator would be aimed at generating diversified example of a specific sentiment label. They also used a state-of-the-art sentiment classifier to guide the generation of sentimental texts. Their architecture also included one multi-class discriminator, which could make generators more focused on generating their own examples of specific sentiment labels, and stay away from other types of sentiments.</p>
<div id="id-5"><img src="/img/posts/generating-empathetic-responses/sentiGAN.png" width="700" alt="SentiGAN Architecture"></div>
<p>The goal of the discriminator is to distinguish between fake texts (texts generated by generators) and real texts with k sentiment types as much as possible. Along with using a well-performed sentiment classifier as evaluators to verify the sentiment accuracy of the generated texts, they also evaluated several other metrics (i.e., fluency, novelty, diversity, intelligibility) to measure the quality of generated texts from different aspects. Their work was mostly focused on generating short sentences (length ≤ 15 words) of two sentiment types (positive and negative).</p>
<h4 id="a-dual-decoder-framework-to-generate-a-response-with-given-sentiment" class="headerLink">
    <a href="#a-dual-decoder-framework-to-generate-a-response-with-given-sentiment" class="header-mark"></a>A Dual-decoder framework to generate a response with given sentiment</h4><div id="id-6"><img src="/img/posts/generating-empathetic-responses/dual_decoder.png" width="400" alt="Dual Decoder Architecture"></div>
<p>Another variation of the idea to generate a response with a fixed target emotion is seen in <em><cite>Xiuyu and Yunfang, 2019<sup id="fnref:22"><a href="#fn:22" class="footnote-ref" role="doc-noteref">22</a></sup></cite></em>. They construct a new conversation dataset in the form of (post, resp1, resp2), where two responses contain opposite sentiment, positive and negative. And then used an architecture with one encoder and two sentiment decoders that could generate emotionally diverse responses.</p>
<h4 id="using-reinforcement-learning-to-reward-future-emotional-states" class="headerLink">
    <a href="#using-reinforcement-learning-to-reward-future-emotional-states" class="header-mark"></a>Using Reinforcement Learning to reward future emotional states</h4><p>While all of the prior work focused on either conditioning the output on a given emotion,or inferring based on the current emotion from the user&rsquo;s input. <em><cite>Shin et al.<sup id="fnref1:22"><a href="#fn:22" class="footnote-ref" role="doc-noteref">22</a></sup></cite></em> instead proposed a &ldquo;Sentiment Look-ahead&rdquo; approach which models the user&rsquo;s future emotional state. They evaluated three different Reinforcement learning strategies with a reward function that provided a higher reward to the generative model when the generated utterance improves the user’s sentiment. This improvement is calculated based upon the three different reward functions that aim to predict the user sentiment for the response to be positive or an improvement or directly uses the actual sentiment for the next user turn. They use a seq-to-seq GRU-based model and dot product attention for modeling policy and use the MIXER algorithm for policy learning.</p>
<h4 id="formalizing-empathy-generation-a-new-dataset-from-facebook-ai-research" class="headerLink">
    <a href="#formalizing-empathy-generation-a-new-dataset-from-facebook-ai-research" class="header-mark"></a>Formalizing Empathy Generation: A new dataset from Facebook AI Research</h4><p>Perhaps the first research to formally define the empathetic response generation was done by <em><cite>Rashkin, Smith, et al. 2019<sup id="fnref:23"><a href="#fn:23" class="footnote-ref" role="doc-noteref">23</a></sup></cite></em>. They released a novel empathetic dialogue dataset, EMPATHETICDIALOGUES, which contains 24,850 conversations about a situation description, gathered from 810 different participants. Each conversation is grounded in a situation, which one participant writes about in association with a given emotion label out of, close to evenly distributed, 32 total emotion labels. This data was explicitly collected with instructions to be empathetic, in a one-on-one setting.</p>
<div id="id-7"><img src="/img/posts/generating-empathetic-responses/fb_dataset.png" width="900" alt="FB Dataset"></div>
<p>Through experiments with Transformer based models, they showed that fine-tuning a dialogue agent on their dataset results in better performance on a novel empathetic dialogue task. They conducted their experiments in two settings: Retrieval- the model was given a large set of candidate responses and it picks the “best” one, Generation- a full Transformer architecture was trained to minimize the negative log-likelihood of the target sequence and predict a sequence of words. They also proposed multiple schemes to augment the pretraining process by incorporating an external pre-trained classifier&rsquo;s signal to nudge the training to include this emotion information and yield better performance. For example, in a multi-task setup, an encoded context representation could be passed to an emotion classifier and a decoder to generate a response. The encoder could then be trained with gradients from both output branches. Similarly, the output from the classifier could either be concatenated with the input or the output of the encoder.</p>
<h4 id="maximizing-positive-arousal" class="headerLink">
    <a href="#maximizing-positive-arousal" class="header-mark"></a>Maximizing Positive Arousal</h4><p><em><cite>Lubis et al. 2018<sup id="fnref:24"><a href="#fn:24" class="footnote-ref" role="doc-noteref">24</a></sup></cite></em> built a system mainly focused on maximizing positive emotion elicitation from the user. Their definition of emotion is based on the circumplex model of affect (valence vs. arousal). They built a model by extending the hierarchical recurrent encoder-decoder (HRED) architecture proposed by <em><cite>Serban et al. 2016<sup id="fnref:25"><a href="#fn:25" class="footnote-ref" role="doc-noteref">25</a></sup></cite></em>. Original HRED consists of a sequence-to-sequence architecture having an utterance encoder, a dialogue encoder, and an utterance decoder.  This research incorporated an emotion encoder (RNN with GRU cells) into the network to capture the emotional context of a dialogue to produce an affect-sensitive response through an Emotion-sensitive HRED (Emo-HRED). The emotion encoder is placed in the same hierarchy as the dialogue encoder, capturing emotion information at the dialogue-turn level, and maintaining the emotion context history throughout the dialogue-turn.</p>
<div id="id-8"><img src="/img/posts/generating-empathetic-responses/emo_hred.png" width="450" alt="EmoHRED"></div>
<p>After reading the input sequence, the dialogue turn is encoded into utterance representation which is then fed into the dialogue encoder to model the sequence of dialogue turns into dialogue context. The dialogue context is then fed into the emotion encoder, which will then be used to model the emotional context. The generation process of the response is conditioned by the concatenation of the dialogue and emotional contexts. Finally, the network is trained using the positive emotion eliciting data. Because of the lack of availability of a large-scale and reliable dataset, the authors proposed selective fine-tuning of the Emo-HRED, limiting the parameter updates to the emotion encoder and utterance decoder only.</p>
<h3 id="current-state-of-the-art-research-on-empathetic-response-generation" class="headerLink">
    <a href="#current-state-of-the-art-research-on-empathetic-response-generation" class="header-mark"></a>Current State-of-the-Art Research on Empathetic Response Generation</h3><p>The sheer pace of progress in NLP makes it difficult to keep track of current state-of-the-art researches. And, often it is difficult to pin-down one research work as the current state-of-the-art, simply because there might be some other research that shows improvement in certain but not all of the shared metrics or different research work might have used completely different dataset for training and evaluation. However, the following two recent papers stand out for the quality of their results for empathetic response generation in dialogue systems on <em><cite>empathetic-dialogues dataset<sup id="fnref1:23"><a href="#fn:23" class="footnote-ref" role="doc-noteref">23</a></sup></cite></em>.</p>
<h4 id="moel-mixture-of-empathetic-listeners" class="headerLink">
    <a href="#moel-mixture-of-empathetic-listeners" class="header-mark"></a>MoEL: Mixture of Empathetic Listeners</h4><p>The authors of <em><cite>this research (Lin et al., 2019)<sup id="fnref:26"><a href="#fn:26" class="footnote-ref" role="doc-noteref">26</a></sup></cite></em> argue that prior researches made assumptions such as- understanding the emotional state of the user is enough for the model to implicitly learn how to respond appropriately without any additional inductive bias. However, this assumption may lead to generic response outputs from the single decoder that is learning to produce all emotions. Some of the other works assume that the emotion to condition the generation on is given as input, which may not always be true.</p>
<p>There could be multiple emotions present in different turns. Hence a dialogue state embedding is also incorporated along with word embedding and standard positional embedding to produce context embedding. This idea was originally proposed by <em><cite>Wolf et al., 2019<sup id="fnref:27"><a href="#fn:27" class="footnote-ref" role="doc-noteref">27</a></sup></cite></em>.</p>
<div id="id-9"><img src="/img/posts/generating-empathetic-responses/moel_emb.PNG" width="1000" alt="MoEL Embeddings"></div>
<p>Similar to the prior art, MoEL first encodes the dialogue context and uses it to recognize the emotional state (out of n possible states). But this architecture contains n decoders, called listeners, which are optimized to react to each context emotion. There is another listener, called meta-listener, that is trained along with other listeners and learns to softly combine the output states of all decoders according to the emotional classification distribution. This idea of having independent specialized experts (Listeners) was originally inspired by <em><cite>Shazeer et al. (2017)<sup id="fnref:28"><a href="#fn:28" class="footnote-ref" role="doc-noteref">28</a></sup></cite></em>.</p>
<div id="id-10"><img src="/img/posts/generating-empathetic-responses/moel_copy.png" width="800" alt="EmoHRED"></div>
<p>The 3-main components in this architecture are described below.</p>
<ul>
<li><strong>Emotion Tracker:</strong> It is simply a standard Transformer encoder that encodes context and also computes a distribution over the possible user emotions. A query token QRY at the beginning of each input sequence, as in BERT, to compute the weighted sum of the output tensor.</li>
<li><strong>Emotion-aware Listeners:</strong> These are standard Transformer decoders that independently attend to the distribution produced by the emotional tracker and compute their own representation. There is also a shared listener that learns shared information for all emotions. The output from the shared listener is expected to be a general representation that can help the model to capture the dialogue context. But each empathetic listener learns how to respond to a particular emotion. Hence, different weights are assigned to each empathetic listener according to the user emotion distribution, while assigning a fixed weight of 1 to the shared listener.</li>
<li><strong>Meta Listener:</strong> Finally, the meta listener takes the weighted sum of representations from the listeners and generates the final response. The intuition is that each listener specializes in a certain emotion and the Meta Listener gathers the opinions generated by multiple listeners to produce the final response.</li>
</ul>
<p>In the experiments conducted on <em><cite>empathetic-dialogues dataset<sup id="fnref2:23"><a href="#fn:23" class="footnote-ref" role="doc-noteref">23</a></sup></cite></em>, MoEL shows improvements over the baseline in Empathy and Relevance, while the baseline had a higher score on Fluency.</p>
<h4 id="mime-mimicking-emotions-for-empathetic-response-generation" class="headerLink">
    <a href="#mime-mimicking-emotions-for-empathetic-response-generation" class="header-mark"></a>MIME: MIMicking Emotions for Empathetic Response Generation</h4><p>Mimicry is one of the key components related to empathy. Research in Psychology shows that mimicry contributes substantially to an empathic response. <em><cite>Sonnby-Borgstrom, 2002<sup id="fnref:29"><a href="#fn:29" class="footnote-ref" role="doc-noteref">29</a></sup></cite></em> proposed that mimicry enables one to automatically share and understand another’s emotions. Their proposal also receives support from studies showing a (notably, weak) correlation between the strength of the mimicry response and trait measures of <em><cite>empathy<sup id="fnref1:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup></cite></em>. Research in neuroscience, such as <em><cite>Carr et al., 2003<sup id="fnref:30"><a href="#fn:30" class="footnote-ref" role="doc-noteref">30</a></sup></cite></em>, show that the empathetic responses often mimic the emotion of the speaker.</p>
<p>Inspired by these ideas, <em><cite>Majumder et al.<sup id="fnref:31"><a href="#fn:31" class="footnote-ref" role="doc-noteref">31</a></sup></cite></em>, presented a proposed at EMNLP 2020 that claims to improve the MoEL research&rsquo;s scores calculated on <em><cite>empathetic-dialogues dataset<sup id="fnref3:23"><a href="#fn:23" class="footnote-ref" role="doc-noteref">23</a></sup></cite></em>. Their work claims that the emotions in the input text should not be treated as a flat structure where all emotions are equal. Instead, an empathetic response should mimic the emotions of a user to a varying degree. So, to improve the empathy and contextual relevance of the responses the authors introduced the following concepts: Emotion Mimicry, Emotion Grouping, and Emotion Stochastic Sampling.</p>
<ul>
<li>
<p><strong>Emotion Mimicry:</strong> As mentioned earlier, empathetic responses often mimic the emotions of the speaker to some degree. For example, positively charged utterances from the users are usually responded with positive emotions, although the response can also be somewhat ambivalent. On the other hand, responding to negatively-charged utterances often requires composite emotions that agree with the user’s emotion, but also tries to comfort them with some positivity, such as hopefulness or silver lining. This work attempts to balance the mimicry of user emotions with context.</p>
</li>
<li>
<p><strong>Emotion Grouping:</strong> The authors split 32 emotion types into two groups containing 13 positive and 19 negative emotions.</p>
</li>
<li>
<p><strong>Emotion Stochastic Sampling:</strong> Stochasticity is added at the emotion-group level for varied responses. This helps in avoiding generic and repetitive response generations.</p>
</li>
</ul>
<p>Similar to <em><cite>Rashkin, Smith, et al. 2019<sup id="fnref4:23"><a href="#fn:23" class="footnote-ref" role="doc-noteref">23</a></sup></cite></em>, MIME uses the output of a trained emotion classifier to infuse emotion into the context representation. The classifier is trained to predict the 32 emotion labels from the Empathetic-Dialogues dataset, and also learns corresponding emotion embeddings from this data. The authors use intuitions to group these 32 emotions into 2 groups -  positive and negative.</p>
<div id="id-11"><img src="/img/posts/generating-empathetic-responses/mime.png" width="900" alt="MiME"></div>
<p>Similar to MoEL, each word is represented as a sum of three embeddings: word embedding, positional embedding, and speaker embedding. Also as in MoEL, inspired by BERT, one additional token is prepended to the context sequence to encode the entirety of the context.</p>
<p>A probability distribution of emotions is sampled for each of the positive and negative emotion groups that corresponds to the emotion of the response. These distributions (called response-emotion distributions) are used to create emotion representations that are then combined and balanced to create a new emotional representation that drives the emotional state during response generation using a Transformer decoder. Sampling from these two distributions achieves Emotion Stochastic Sampling, and the sampling combined with the corresponding pooled emotion embeddings enables two distinct response-emotion-refined context representations — mimicking and non-mimicking, and achieves Emotion Mimicry.</p>
<p>MIME showed improved empathy and Relevance scores over MoEL, which the authors attribute to appropriately mimicking the user’s emotion through stochasticity, positive/negative grouping, and sharing of emotion embeddings between classifier and decoder. However, MoEL still showed a better score on Fluency. The author hypothesizes that the drop in fluency could be because of the very structure of shared input to the decoder that is coercing the decoder to focus more on emotionally-apt tokens of the response than appropriate stop-words that have no intrinsic emotional content but lead to grammatical clarity.</p>
<h2 id="conclusion" class="headerLink">
    <a href="#conclusion" class="header-mark"></a>Conclusion</h2><p>In this article, we looked at what Empathy means from a philosophical, psychological, and neuroscience perspective. Then we did a deep dive into research on making Empathetic NLU systems. We went through several datasets and model architectures, including a peek into the current state-of-the-art systems that can generate empathetic responses in conversational dialogue systems. I hope you learned some new things from this post. And, I will love to hear your feedback in the comments below.</p>
<h2 id="references" class="headerLink">
    <a href="#references" class="header-mark"></a>References</h2><div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p><a href="https://plato.stanford.edu/entries/empathy/" target="_blank" rel="noopener noreferrer">Empathy, Stanford Encyclopedia of Philosophy</a>&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p><a href="https://karlamclaren.com/einfuhlung-and-empathy/" target="_blank" rel="noopener noreferrer">Einfühlung and Empathy: What do they mean?, Karal McLaren</a>&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p><a href="https://psycnet.apa.org/record/1951-04352-001" target="_blank" rel="noopener noreferrer">Personality and Empathy, Rosalind Daymond</a>&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4">
<p><a href="https://greatergood.berkeley.edu/images/uploads/Singer_2009.pdf" target="_blank" rel="noopener noreferrer">The Social Neuroscience of Empathy, Tania Singer and Claus Lamm</a>&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5">
<p><a href="https://psycnet.apa.org/record/1988-98392-000" target="_blank" rel="noopener noreferrer">Machiavellian intelligence: Social expertise and the evolution of intellect in monkeys, apes, and humans, Richard Byrne</a>&#160;<a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:6">
<p><a href="https://link.springer.com/chapter/10.1007/978-0-387-30715-2_20" target="_blank" rel="noopener noreferrer">Empathy: A social psychological approach, Mark H. Davis</a>&#160;<a href="#fnref:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:7">
<p><a href="https://www.jstor.org/stable/j.ctt9qg24m.11" target="_blank" rel="noopener noreferrer">Altruism and human nature: Resolving the evolutionary paradox, Ian Vine</a>&#160;<a href="#fnref:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:8">
<p><a href="https://www.amazon.com/dp/1557984107" target="_blank" rel="noopener noreferrer">Empathy Reconsidered: New Directions in Psychotherapy, Arthur Bohart, Leslie Greenberg</a>&#160;<a href="#fnref:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:9">
<p><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1316134/pdf/12389763.pdf" target="_blank" rel="noopener noreferrer">Empathy and quality of care, Stewart Mercer; William Reynolds</a>&#160;<a href="#fnref:9" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:10">
<p><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5010859/" target="_blank" rel="noopener noreferrer">Analyzing the Language of Therapist Empathy in Motivational Interview based Psychotherapy, Xiao et al</a>&#160;<a href="#fnref:10" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:11">
<p><a href="https://sail.usc.edu/~malandra/files/papers/interspeech2015b.pdf" target="_blank" rel="noopener noreferrer">Predicting Therapist Empathy in Motivational Interviews using Language Features Inspired by Psycholinguistic Norms, Gibson et al.</a>&#160;<a href="#fnref:11" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:12">
<p><a href="https://www.aclweb.org/anthology/I17-2042/" target="_blank" rel="noopener noreferrer">Identifying Empathetic Messages in Online Health Communities, Khanour et al.</a>&#160;<a href="#fnref:12" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:13">
<p><a href="https://www.aclweb.org/anthology/D18-1507/" target="_blank" rel="noopener noreferrer">Modeling Empathy and Distress in Reaction to News Stories, Buechel et al.</a>&#160;<a href="#fnref:13" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:14">
<p><a href="https://www.aclweb.org/anthology/P17-1131/" target="_blank" rel="noopener noreferrer">Understanding and Predicting Empathic Behavior in Counseling Therapy, Perez-Rosas et al.</a>&#160;<a href="#fnref:14" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:15">
<p><a href="https://www.aclweb.org/anthology/N16-3018/" target="_blank" rel="noopener noreferrer">Zara The Supergirl: An Empathetic Personality Recognition System, Fung, Dey et al.</a>&#160;<a href="#fnref:15" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:16">
<p><a href="https://www.isca-speech.org/archive/Interspeech_2017/pdfs/2050.PDF" target="_blank" rel="noopener noreferrer">Nora the Empathetic Psychologist, Winata, Kampman et al.</a>&#160;<a href="#fnref:16" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:17">
<p><a href="https://www.aclweb.org/anthology/D16-1110/" target="_blank" rel="noopener noreferrer">Real-Time Speech Emotion and Sentiment Recognition for Interactive Dialogue Systems, Bertero, Siddique et al.</a>&#160;<a href="#fnref:17" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:18">
<p><a href="https://arxiv.org/abs/1704.01074" target="_blank" rel="noopener noreferrer">Emotional Chatting Machine: Emotional Conversation Generation with Internal and External Memory, Zhou, Huang et al.</a>&#160;<a href="#fnref:18" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:19">
<p><a href="https://www.aclweb.org/anthology/P17-1059/" target="_blank" rel="noopener noreferrer">Affect-lm: A neural language model for customizable affective text generation, Ghosh et al.</a>&#160;<a href="#fnref:19" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:20">
<p><a href="https://www.aclweb.org/anthology/P18-1104/" target="_blank" rel="noopener noreferrer">MojiTalk: Generating Emotional Responses at Scale, Zhou and Wang, 2018</a>&#160;<a href="#fnref:20" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:21">
<p><a href="https://www.ijcai.org/Proceedings/2018/618" target="_blank" rel="noopener noreferrer">SentiGAN: Generating Sentimental Texts via Mixture Adversarial Networks, Wang and Wan, 2018</a>&#160;<a href="#fnref:21" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:22">
<p><a href="https://arxiv.org/abs/1905.06597" target="_blank" rel="noopener noreferrer">A Simple Dual-decoder Model for Generating Response with Sentiment, Xiuyu and Yunfang, 2019</a>; <a href="https://github.com/HLTCHKUST/sentiment-lookahead" target="_blank" rel="noopener noreferrer">[Source Code]</a>&#160;<a href="#fnref:22" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:22" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:23">
<p><a href="https://arxiv.org/abs/1811.00207v2" target="_blank" rel="noopener noreferrer">I Know The Feeling: Learning To Converse With Empathy, Rashkin, Smith et al. 2019</a>&#160;<a href="#fnref:23" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:23" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:23" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref3:23" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref4:23" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:24">
<p><a href="https://aaai.org/ocs/index.php/AAAI/AAAI18/paper/viewPaper/16317" target="_blank" rel="noopener noreferrer">Eliciting Positive Emotion through Affect-Sensitive Dialogue Response Generation: A Neural Network Approach, Lubis et al. 2018</a>&#160;<a href="#fnref:24" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:25">
<p><a href="https://arxiv.org/abs/1507.04808" target="_blank" rel="noopener noreferrer">Building End-To-End Dialogue Systems Using Generative Hierarchical Neural Network Models, Serban et al. 2016</a>&#160;<a href="#fnref:25" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:26">
<p><a href="https://arxiv.org/abs/1908.07687" target="_blank" rel="noopener noreferrer">MoEL: Mixture of Empathetic Listeners, Lin et al., 2019</a>; <a href="https://github.com/HLTCHKUST/MoEL" target="_blank" rel="noopener noreferrer">[Source Code]</a>&#160;<a href="#fnref:26" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:27">
<p><a href="https://arxiv.org/abs/1901.08149" target="_blank" rel="noopener noreferrer">TransferTransfo: A Transfer Learning Approach for Neural Network Based Conversational Agents, Wolf et al., 2019</a>&#160;<a href="#fnref:27" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:28">
<p><a href="https://arxiv.org/abs/1701.06538" target="_blank" rel="noopener noreferrer">Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer, Shazeer et al. (2017)</a>&#160;<a href="#fnref:28" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:29">
<p><a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/1467-9450.00312" target="_blank" rel="noopener noreferrer">Automatic mimicry reactions as related to differences in emotional empathy, Sonnby–Borgström, 2008</a>&#160;<a href="#fnref:29" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:30">
<p><a href="https://www.pnas.org/content/100/9/5497" target="_blank" rel="noopener noreferrer">Neural mechanisms of empathy in humans: A relay from neural systems for imitation to limbic areas, Carr et al., 2003</a>&#160;<a href="#fnref:30" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:31">
<p><a href="https://arxiv.org/abs/2010.01454" target="_blank" rel="noopener noreferrer">MIME: MIMicking Emotions for Empathetic Response Generation, Majumder et al. 2020</a> <a href="https://github.com/declare-lab/MIME" target="_blank" rel="noopener noreferrer">[Source Code]</a>&#160;<a href="#fnref:31" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div></div>
		
        


<h2>Related Content</h2>
<div class="related-container">
    <div class="related-item-container">
            <div class="related-image">
                <a href="/posts/2023/03/pairing-for-representation/"><img
        
        loading="lazy"
        src="/posts/2023/03/pairing-for-representation/featured-image-preview.webp"
        srcset="/posts/2023/03/pairing-for-representation/featured-image-preview.webp, /posts/2023/03/pairing-for-representation/featured-image-preview.webp 1.5x, /posts/2023/03/pairing-for-representation/featured-image-preview.webp 2x"
        sizes="auto"
        alt="/posts/2023/03/pairing-for-representation/featured-image-preview.webp"
        title="Recognizing feelings in the conversation partner and replying empathetically is a trivial skill for humans. But how can we infuse empathy into responses generated by a conversational dialogue agent or any of the text generation algorithm in Natural Language Processing? In this article, I will describe what empathy means through the lens of various academic disciplines and then do an in-depth review of the prior and current state-of-the-art NLU systems that can simulate empathy." height="200" width="400"></a>
            </div><h2 class="related-title">
                <a href="/posts/2023/03/pairing-for-representation/">Positive and Negative Sampling Strategies for Representation Learning in Semantic Search</a>
            </h2>
        </div>
    <div class="related-item-container">
            <div class="related-image">
                <a href="/posts/2023/03/llm-for-text-ranking/"><img
        
        loading="lazy"
        src="/posts/2023/03/llm-for-text-ranking/featured-image-preview.webp"
        srcset="/posts/2023/03/llm-for-text-ranking/featured-image-preview.webp, /posts/2023/03/llm-for-text-ranking/featured-image-preview.webp 1.5x, /posts/2023/03/llm-for-text-ranking/featured-image-preview.webp 2x"
        sizes="auto"
        alt="/posts/2023/03/llm-for-text-ranking/featured-image-preview.webp"
        title="Recognizing feelings in the conversation partner and replying empathetically is a trivial skill for humans. But how can we infuse empathy into responses generated by a conversational dialogue agent or any of the text generation algorithm in Natural Language Processing? In this article, I will describe what empathy means through the lens of various academic disciplines and then do an in-depth review of the prior and current state-of-the-art NLU systems that can simulate empathy." height="200" width="400"></a>
            </div><h2 class="related-title">
                <a href="/posts/2023/03/llm-for-text-ranking/">Zero and Few Shot Text Retrieval and Ranking Using Large Language Models</a>
            </h2>
        </div>
    <div class="related-item-container">
            <div class="related-image">
                <a href="/posts/2023/03/reranking-on-edge/"><img
        
        loading="lazy"
        src="/posts/2023/03/reranking-on-edge/featured-image-preview.webp"
        srcset="/posts/2023/03/reranking-on-edge/featured-image-preview.webp, /posts/2023/03/reranking-on-edge/featured-image-preview.webp 1.5x, /posts/2023/03/reranking-on-edge/featured-image-preview.webp 2x"
        sizes="auto"
        alt="/posts/2023/03/reranking-on-edge/featured-image-preview.webp"
        title="Recognizing feelings in the conversation partner and replying empathetically is a trivial skill for humans. But how can we infuse empathy into responses generated by a conversational dialogue agent or any of the text generation algorithm in Natural Language Processing? In this article, I will describe what empathy means through the lens of various academic disciplines and then do an in-depth review of the prior and current state-of-the-art NLU systems that can simulate empathy." height="200" width="400"></a>
            </div><h2 class="related-title">
                <a href="/posts/2023/03/reranking-on-edge/">Next Gen Recommender Systems: Real-time reranking on mobile devices</a>
            </h2>
        </div>
    <div class="related-item-container">
            <div class="related-image">
                <a href="/posts/2023/03/two-tower-model/"><img
        
        loading="lazy"
        src="/posts/2023/03/two-tower-model/featured-image-preview.webp"
        srcset="/posts/2023/03/two-tower-model/featured-image-preview.webp, /posts/2023/03/two-tower-model/featured-image-preview.webp 1.5x, /posts/2023/03/two-tower-model/featured-image-preview.webp 2x"
        sizes="auto"
        alt="/posts/2023/03/two-tower-model/featured-image-preview.webp"
        title="Recognizing feelings in the conversation partner and replying empathetically is a trivial skill for humans. But how can we infuse empathy into responses generated by a conversational dialogue agent or any of the text generation algorithm in Natural Language Processing? In this article, I will describe what empathy means through the lens of various academic disciplines and then do an in-depth review of the prior and current state-of-the-art NLU systems that can simulate empathy." height="200" width="400"></a>
            </div><h2 class="related-title">
                <a href="/posts/2023/03/two-tower-model/">Two Tower Model Architecture: Current State and Promising Extensions</a>
            </h2>
        </div>
    <div class="related-item-container">
            <div class="related-image">
                <a href="/posts/2023/01/dl-for-forecasting/"><img
        
        loading="lazy"
        src="/posts/2023/01/dl-for-forecasting/featured-image-preview.webp"
        srcset="/posts/2023/01/dl-for-forecasting/featured-image-preview.webp, /posts/2023/01/dl-for-forecasting/featured-image-preview.webp 1.5x, /posts/2023/01/dl-for-forecasting/featured-image-preview.webp 2x"
        sizes="auto"
        alt="/posts/2023/01/dl-for-forecasting/featured-image-preview.webp"
        title="Recognizing feelings in the conversation partner and replying empathetically is a trivial skill for humans. But how can we infuse empathy into responses generated by a conversational dialogue agent or any of the text generation algorithm in Natural Language Processing? In this article, I will describe what empathy means through the lens of various academic disciplines and then do an in-depth review of the prior and current state-of-the-art NLU systems that can simulate empathy." height="200" width="400"></a>
            </div><h2 class="related-title">
                <a href="/posts/2023/01/dl-for-forecasting/">Specialized Deep Learning Architectures for Time Series Forecasting</a>
            </h2>
        </div>
    

</div>


        <script src="https://f.convertkit.com/ckjs/ck.5.js"></script>
<form action="https://app.convertkit.com/forms/4932644/subscriptions" class="seva-form formkit-form" method="post"
      data-sv-form="4932644" data-uid="e309c832a6" data-format="inline" data-version="5"
      data-options="{&quot;settings&quot;:{&quot;after_subscribe&quot;:{&quot;action&quot;:&quot;message&quot;,&quot;success_message&quot;:&quot;Success! Now check your email to confirm your subscription.&quot;,&quot;redirect_url&quot;:&quot;&quot;},&quot;analytics&quot;:{&quot;google&quot;:null,&quot;fathom&quot;:null,&quot;facebook&quot;:null,&quot;segment&quot;:null,&quot;pinterest&quot;:null,&quot;sparkloop&quot;:null,&quot;googletagmanager&quot;:null},&quot;modal&quot;:{&quot;trigger&quot;:&quot;timer&quot;,&quot;scroll_percentage&quot;:null,&quot;timer&quot;:5,&quot;devices&quot;:&quot;all&quot;,&quot;show_once_every&quot;:15},&quot;powered_by&quot;:{&quot;show&quot;:true,&quot;url&quot;:&quot;https://convertkit.com/features/forms?utm_campaign=poweredby&amp;utm_content=form&amp;utm_medium=referral&amp;utm_source=dynamic&quot;},&quot;recaptcha&quot;:{&quot;enabled&quot;:false},&quot;return_visitor&quot;:{&quot;action&quot;:&quot;show&quot;,&quot;custom_content&quot;:&quot;&quot;},&quot;slide_in&quot;:{&quot;display_in&quot;:&quot;bottom_right&quot;,&quot;trigger&quot;:&quot;timer&quot;,&quot;scroll_percentage&quot;:null,&quot;timer&quot;:5,&quot;devices&quot;:&quot;all&quot;,&quot;show_once_every&quot;:15},&quot;sticky_bar&quot;:{&quot;display_in&quot;:&quot;top&quot;,&quot;trigger&quot;:&quot;timer&quot;,&quot;scroll_percentage&quot;:null,&quot;timer&quot;:5,&quot;devices&quot;:&quot;all&quot;,&quot;show_once_every&quot;:15}},&quot;version&quot;:&quot;5&quot;}"
      min-width="400 500 600 700 800"
      style="background-color: rgb(249, 250, 251); border-radius: 4px;margin: 1.5rem auto 0rem">
      <div class="formkit-background" style="opacity: 0.33;"></div>
      <div data-style="minimal">
            <div class="formkit-header" data-element="header"
                  style="color: rgb(77, 77, 77); font-size: 27px; font-weight: 700;">
                  <h2>Be the First to Know</h2>
            </div>
            <div class="formkit-subheader" data-element="subheader" style="color: rgb(104, 104, 104); font-size: 18px;">
                  <p>Subscribe to get notified when I write a new post.</p>
            </div>
            <ul class="formkit-alert formkit-alert-error" data-element="errors" data-group="alert"></ul>
            <div data-element="fields" data-stacked="false" class="seva-fields formkit-fields">
                  <div class="formkit-field"><input class="formkit-input" name="email_address"
                              aria-label="Email Address" placeholder="Email Address" required="" type="email"
                              style="color: rgb(0, 0, 0); border-color: rgb(227, 227, 227); border-radius: 4px; font-weight: 400;">
                  </div><button data-element="submit" class="formkit-submit formkit-submit"
                        style="color: rgb(255, 255, 255); background-color: rgb(22, 119, 190); border-radius: 4px; font-weight: 400;">
                        <div class="formkit-spinner">
                              <div></div>
                              <div></div>
                              <div></div>
                        </div><span class="">Subscribe</span>
                  </button>
            </div>
            <div class="formkit-guarantee" data-element="guarantee"
                  style="color: rgb(77, 77, 77); font-size: 13px; font-weight: 400;">
                  <p>We won't send you spam. Unsubscribe at any time.</p>
            </div>
            <div class="formkit-powered-by-convertkit-container"><a
                        href="https://convertkit.com/features/forms?utm_campaign=poweredby&amp;utm_content=form&amp;utm_medium=referral&amp;utm_source=dynamic"
                        data-element="powered-by" class="formkit-powered-by-convertkit" data-variant="dark"
                        target="_blank" rel="nofollow">Built with ConvertKit</a></div>
      </div>
      <style>
            .formkit-form[data-uid="e309c832a6"] * {
                  box-sizing: border-box;
            }

            .formkit-form[data-uid="e309c832a6"] {
                  -webkit-font-smoothing: antialiased;
                  -moz-osx-font-smoothing: grayscale;
            }

            .formkit-form[data-uid="e309c832a6"] legend {
                  border: none;
                  font-size: inherit;
                  margin-bottom: 10px;
                  padding: 0;
                  position: relative;
                  display: table;
            }

            .formkit-form[data-uid="e309c832a6"] fieldset {
                  border: 0;
                  padding: 0.01em 0 0 0;
                  margin: 0;
                  min-width: 0;
            }

            .formkit-form[data-uid="e309c832a6"] body:not(:-moz-handler-blocked) fieldset {
                  display: table-cell;
            }

            .formkit-form[data-uid="e309c832a6"] h1,
            .formkit-form[data-uid="e309c832a6"] h2,
            .formkit-form[data-uid="e309c832a6"] h3,
            .formkit-form[data-uid="e309c832a6"] h4,
            .formkit-form[data-uid="e309c832a6"] h5,
            .formkit-form[data-uid="e309c832a6"] h6 {
                  color: inherit;
                  font-size: inherit;
                  font-weight: inherit;
            }

            .formkit-form[data-uid="e309c832a6"] h2 {
                  font-size: 1.5em;
                  margin: 1em 0;
            }

            .formkit-form[data-uid="e309c832a6"] h3 {
                  font-size: 1.17em;
                  margin: 1em 0;
            }

            .formkit-form[data-uid="e309c832a6"] p {
                  color: inherit;
                  font-size: inherit;
                  font-weight: inherit;
            }

            .formkit-form[data-uid="e309c832a6"] ol:not([template-default]),
            .formkit-form[data-uid="e309c832a6"] ul:not([template-default]),
            .formkit-form[data-uid="e309c832a6"] blockquote:not([template-default]) {
                  text-align: left;
            }

            .formkit-form[data-uid="e309c832a6"] p:not([template-default]),
            .formkit-form[data-uid="e309c832a6"] hr:not([template-default]),
            .formkit-form[data-uid="e309c832a6"] blockquote:not([template-default]),
            .formkit-form[data-uid="e309c832a6"] ol:not([template-default]),
            .formkit-form[data-uid="e309c832a6"] ul:not([template-default]) {
                  color: inherit;
                  font-style: initial;
            }

            .formkit-form[data-uid="e309c832a6"] .ordered-list,
            .formkit-form[data-uid="e309c832a6"] .unordered-list {
                  list-style-position: outside !important;
                  padding-left: 1em;
            }

            .formkit-form[data-uid="e309c832a6"] .list-item {
                  padding-left: 0;
            }

            .formkit-form[data-uid="e309c832a6"][data-format="modal"] {
                  display: none;
            }

            .formkit-form[data-uid="e309c832a6"][data-format="slide in"] {
                  display: none;
            }

            .formkit-form[data-uid="e309c832a6"][data-format="sticky bar"] {
                  display: none;
            }

            .formkit-sticky-bar .formkit-form[data-uid="e309c832a6"][data-format="sticky bar"] {
                  display: block;
            }

            .formkit-form[data-uid="e309c832a6"] .formkit-input,
            .formkit-form[data-uid="e309c832a6"] .formkit-select,
            .formkit-form[data-uid="e309c832a6"] .formkit-checkboxes {
                  width: 100%;
            }

            .formkit-form[data-uid="e309c832a6"] .formkit-button,
            .formkit-form[data-uid="e309c832a6"] .formkit-submit {
                  border: 0;
                  border-radius: 5px;
                  color: #ffffff;
                  cursor: pointer;
                  display: inline-block;
                  text-align: center;
                  font-size: 15px;
                  font-weight: 500;
                  cursor: pointer;
                  margin-bottom: 15px;
                  overflow: hidden;
                  padding: 0;
                  position: relative;
                  vertical-align: middle;
            }

            .formkit-form[data-uid="e309c832a6"] .formkit-button:hover,
            .formkit-form[data-uid="e309c832a6"] .formkit-submit:hover,
            .formkit-form[data-uid="e309c832a6"] .formkit-button:focus,
            .formkit-form[data-uid="e309c832a6"] .formkit-submit:focus {
                  outline: none;
            }

            .formkit-form[data-uid="e309c832a6"] .formkit-button:hover>span,
            .formkit-form[data-uid="e309c832a6"] .formkit-submit:hover>span,
            .formkit-form[data-uid="e309c832a6"] .formkit-button:focus>span,
            .formkit-form[data-uid="e309c832a6"] .formkit-submit:focus>span {
                  background-color: rgba(0, 0, 0, 0.1);
            }

            .formkit-form[data-uid="e309c832a6"] .formkit-button>span,
            .formkit-form[data-uid="e309c832a6"] .formkit-submit>span {
                  display: block;
                  -webkit-transition: all 300ms ease-in-out;
                  transition: all 300ms ease-in-out;
                  padding: 12px 24px;
            }

            .formkit-form[data-uid="e309c832a6"] .formkit-input {
                  background: #ffffff;
                  font-size: 15px;
                  padding: 12px;
                  border: 1px solid #e3e3e3;
                  -webkit-flex: 1 0 auto;
                  -ms-flex: 1 0 auto;
                  flex: 1 0 auto;
                  line-height: 1.4;
                  margin: 0;
                  -webkit-transition: border-color ease-out 300ms;
                  transition: border-color ease-out 300ms;
            }

            .formkit-form[data-uid="e309c832a6"] .formkit-input:focus {
                  outline: none;
                  border-color: #1677be;
                  -webkit-transition: border-color ease 300ms;
                  transition: border-color ease 300ms;
            }

            .formkit-form[data-uid="e309c832a6"] .formkit-input::-webkit-input-placeholder {
                  color: inherit;
                  opacity: 0.8;
            }

            .formkit-form[data-uid="e309c832a6"] .formkit-input::-moz-placeholder {
                  color: inherit;
                  opacity: 0.8;
            }

            .formkit-form[data-uid="e309c832a6"] .formkit-input:-ms-input-placeholder {
                  color: inherit;
                  opacity: 0.8;
            }

            .formkit-form[data-uid="e309c832a6"] .formkit-input::placeholder {
                  color: inherit;
                  opacity: 0.8;
            }

            .formkit-form[data-uid="e309c832a6"] [data-group="dropdown"] {
                  position: relative;
                  display: inline-block;
                  width: 100%;
            }

            .formkit-form[data-uid="e309c832a6"] [data-group="dropdown"]::before {
                  content: "";
                  top: calc(50% - 2.5px);
                  right: 10px;
                  position: absolute;
                  pointer-events: none;
                  border-color: #4f4f4f transparent transparent transparent;
                  border-style: solid;
                  border-width: 6px 6px 0 6px;
                  height: 0;
                  width: 0;
                  z-index: 999;
            }

            .formkit-form[data-uid="e309c832a6"] [data-group="dropdown"] select {
                  height: auto;
                  width: 100%;
                  cursor: pointer;
                  color: #333333;
                  line-height: 1.4;
                  margin-bottom: 0;
                  padding: 0 6px;
                  -webkit-appearance: none;
                  -moz-appearance: none;
                  appearance: none;
                  font-size: 15px;
                  padding: 12px;
                  padding-right: 25px;
                  border: 1px solid #e3e3e3;
                  background: #ffffff;
            }

            .formkit-form[data-uid="e309c832a6"] [data-group="dropdown"] select:focus {
                  outline: none;
            }

            .formkit-form[data-uid="e309c832a6"] [data-group="checkboxes"] {
                  text-align: left;
                  margin: 0;
            }

            .formkit-form[data-uid="e309c832a6"] [data-group="checkboxes"] [data-group="checkbox"] {
                  margin-bottom: 10px;
            }

            .formkit-form[data-uid="e309c832a6"] [data-group="checkboxes"] [data-group="checkbox"] * {
                  cursor: pointer;
            }

            .formkit-form[data-uid="e309c832a6"] [data-group="checkboxes"] [data-group="checkbox"]:last-of-type {
                  margin-bottom: 0;
            }

            .formkit-form[data-uid="e309c832a6"] [data-group="checkboxes"] [data-group="checkbox"] input[type="checkbox"] {
                  display: none;
            }

            .formkit-form[data-uid="e309c832a6"] [data-group="checkboxes"] [data-group="checkbox"] input[type="checkbox"]+label::after {
                  content: none;
            }

            .formkit-form[data-uid="e309c832a6"] [data-group="checkboxes"] [data-group="checkbox"] input[type="checkbox"]:checked+label::after {
                  border-color: #ffffff;
                  content: "";
            }

            .formkit-form[data-uid="e309c832a6"] [data-group="checkboxes"] [data-group="checkbox"] input[type="checkbox"]:checked+label::before {
                  background: #10bf7a;
                  border-color: #10bf7a;
            }

            .formkit-form[data-uid="e309c832a6"] [data-group="checkboxes"] [data-group="checkbox"] label {
                  position: relative;
                  display: inline-block;
                  padding-left: 28px;
            }

            .formkit-form[data-uid="e309c832a6"] [data-group="checkboxes"] [data-group="checkbox"] label::before,
            .formkit-form[data-uid="e309c832a6"] [data-group="checkboxes"] [data-group="checkbox"] label::after {
                  position: absolute;
                  content: "";
                  display: inline-block;
            }

            .formkit-form[data-uid="e309c832a6"] [data-group="checkboxes"] [data-group="checkbox"] label::before {
                  height: 16px;
                  width: 16px;
                  border: 1px solid #e3e3e3;
                  background: #ffffff;
                  left: 0px;
                  top: 3px;
            }

            .formkit-form[data-uid="e309c832a6"] [data-group="checkboxes"] [data-group="checkbox"] label::after {
                  height: 4px;
                  width: 8px;
                  border-left: 2px solid #4d4d4d;
                  border-bottom: 2px solid #4d4d4d;
                  -webkit-transform: rotate(-45deg);
                  -ms-transform: rotate(-45deg);
                  transform: rotate(-45deg);
                  left: 4px;
                  top: 8px;
            }

            .formkit-form[data-uid="e309c832a6"] .formkit-alert {
                  background: #f9fafb;
                  border: 1px solid #e3e3e3;
                  border-radius: 5px;
                  -webkit-flex: 1 0 auto;
                  -ms-flex: 1 0 auto;
                  flex: 1 0 auto;
                  list-style: none;
                  margin: 25px auto;
                  padding: 12px;
                  text-align: center;
                  width: 100%;
            }

            .formkit-form[data-uid="e309c832a6"] .formkit-alert:empty {
                  display: none;
            }

            .formkit-form[data-uid="e309c832a6"] .formkit-alert-success {
                  background: #d3fbeb;
                  border-color: #10bf7a;
                  color: #0c905c;
            }

            .formkit-form[data-uid="e309c832a6"] .formkit-alert-error {
                  background: #fde8e2;
                  border-color: #f2643b;
                  color: #ea4110;
            }

            .formkit-form[data-uid="e309c832a6"] .formkit-spinner {
                  display: -webkit-box;
                  display: -webkit-flex;
                  display: -ms-flexbox;
                  display: flex;
                  height: 0px;
                  width: 0px;
                  margin: 0 auto;
                  position: absolute;
                  top: 0;
                  left: 0;
                  right: 0;
                  width: 0px;
                  overflow: hidden;
                  text-align: center;
                  -webkit-transition: all 300ms ease-in-out;
                  transition: all 300ms ease-in-out;
            }

            .formkit-form[data-uid="e309c832a6"] .formkit-spinner>div {
                  margin: auto;
                  width: 12px;
                  height: 12px;
                  background-color: #fff;
                  opacity: 0.3;
                  border-radius: 100%;
                  display: inline-block;
                  -webkit-animation: formkit-bouncedelay-formkit-form-data-uid-e309c832a6- 1.4s infinite ease-in-out both;
                  animation: formkit-bouncedelay-formkit-form-data-uid-e309c832a6- 1.4s infinite ease-in-out both;
            }

            .formkit-form[data-uid="e309c832a6"] .formkit-spinner>div:nth-child(1) {
                  -webkit-animation-delay: -0.32s;
                  animation-delay: -0.32s;
            }

            .formkit-form[data-uid="e309c832a6"] .formkit-spinner>div:nth-child(2) {
                  -webkit-animation-delay: -0.16s;
                  animation-delay: -0.16s;
            }

            .formkit-form[data-uid="e309c832a6"] .formkit-submit[data-active] .formkit-spinner {
                  opacity: 1;
                  height: 100%;
                  width: 50px;
            }

            .formkit-form[data-uid="e309c832a6"] .formkit-submit[data-active] .formkit-spinner~span {
                  opacity: 0;
            }

            .formkit-form[data-uid="e309c832a6"] .formkit-powered-by[data-active="false"] {
                  opacity: 0.35;
            }

            .formkit-form[data-uid="e309c832a6"] .formkit-powered-by-convertkit-container {
                  display: -webkit-box;
                  display: -webkit-flex;
                  display: -ms-flexbox;
                  display: flex;
                  width: 100%;
                  z-index: 5;
                  margin: 10px 0;
                  position: relative;
            }

            .formkit-form[data-uid="e309c832a6"] .formkit-powered-by-convertkit-container[data-active="false"] {
                  opacity: 0.35;
            }

            .formkit-form[data-uid="e309c832a6"] .formkit-powered-by-convertkit {
                  -webkit-align-items: center;
                  -webkit-box-align: center;
                  -ms-flex-align: center;
                  align-items: center;
                  background-color: #ffffff;
                  border: 1px solid #dde2e7;
                  border-radius: 4px;
                  color: #373f45;
                  cursor: pointer;
                  display: block;
                  height: 36px;
                  margin: 0 auto;
                  opacity: 0.95;
                  padding: 0;
                  -webkit-text-decoration: none;
                  text-decoration: none;
                  text-indent: 100%;
                  -webkit-transition: ease-in-out all 200ms;
                  transition: ease-in-out all 200ms;
                  white-space: nowrap;
                  overflow: hidden;
                  -webkit-user-select: none;
                  -moz-user-select: none;
                  -ms-user-select: none;
                  user-select: none;
                  width: 190px;
                  background-repeat: no-repeat;
                  background-position: center;
                  background-image: url("data:image/svg+xml;charset=utf8,%3Csvg width='162' height='20' viewBox='0 0 162 20' fill='none' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath d='M83.0561 15.2457C86.675 15.2457 89.4722 12.5154 89.4722 9.14749C89.4722 5.99211 86.8443 4.06563 85.1038 4.06563C82.6801 4.06563 80.7373 5.76407 80.4605 8.28551C80.4092 8.75244 80.0387 9.14403 79.5686 9.14069C78.7871 9.13509 77.6507 9.12841 76.9314 9.13092C76.6217 9.13199 76.3658 8.88106 76.381 8.57196C76.4895 6.38513 77.2218 4.3404 78.618 2.76974C80.1695 1.02445 82.4289 0 85.1038 0C89.5979 0 93.8406 4.07791 93.8406 9.14749C93.8406 14.7608 89.1832 19.3113 83.1517 19.3113C78.8502 19.3113 74.5179 16.5041 73.0053 12.5795C72.9999 12.565 72.9986 12.5492 73.0015 12.534C73.0218 12.4179 73.0617 12.3118 73.1011 12.2074C73.1583 12.0555 73.2143 11.907 73.2062 11.7359L73.18 11.1892C73.174 11.0569 73.2075 10.9258 73.2764 10.8127C73.3452 10.6995 73.4463 10.6094 73.5666 10.554L73.7852 10.4523C73.9077 10.3957 74.0148 10.3105 74.0976 10.204C74.1803 10.0974 74.2363 9.97252 74.2608 9.83983C74.3341 9.43894 74.6865 9.14749 75.0979 9.14749C75.7404 9.14749 76.299 9.57412 76.5088 10.1806C77.5188 13.1 79.1245 15.2457 83.0561 15.2457Z' fill='%23373F45'/%3E%3Cpath d='M155.758 6.91365C155.028 6.91365 154.804 6.47916 154.804 5.98857C154.804 5.46997 154.986 5.06348 155.758 5.06348C156.53 5.06348 156.712 5.46997 156.712 5.98857C156.712 6.47905 156.516 6.91365 155.758 6.91365ZM142.441 12.9304V9.32833L141.415 9.32323V8.90392C141.415 8.44719 141.786 8.07758 142.244 8.07986L142.441 8.08095V6.55306L144.082 6.09057V8.08073H145.569V8.50416C145.569 8.61242 145.548 8.71961 145.506 8.81961C145.465 8.91961 145.404 9.01047 145.328 9.08699C145.251 9.16351 145.16 9.2242 145.06 9.26559C144.96 9.30698 144.853 9.32826 144.745 9.32822H144.082V12.7201C144.082 13.2423 144.378 13.4256 144.76 13.4887C145.209 13.5629 145.583 13.888 145.583 14.343V14.9626C144.029 14.9626 142.441 14.8942 142.441 12.9304Z' fill='%23373F45'/%3E%3Cpath d='M110.058 7.92554C108.417 7.88344 106.396 8.92062 106.396 11.5137C106.396 14.0646 108.417 15.0738 110.058 15.0318C111.742 15.0738 113.748 14.0646 113.748 11.5137C113.748 8.92062 111.742 7.88344 110.058 7.92554ZM110.07 13.7586C108.878 13.7586 108.032 12.8905 108.032 11.461C108.032 10.1013 108.878 9.20569 110.071 9.20569C111.263 9.20569 112.101 10.0995 112.101 11.459C112.101 12.8887 111.263 13.7586 110.07 13.7586Z' fill='%23373F45'/%3E%3Cpath d='M118.06 7.94098C119.491 7.94098 120.978 8.33337 120.978 11.1366V14.893H120.063C119.608 14.893 119.238 14.524 119.238 14.0689V10.9965C119.238 9.66506 118.747 9.16047 117.891 9.16047C117.414 9.16047 116.797 9.52486 116.502 9.81915V14.069C116.502 14.1773 116.481 14.2845 116.44 14.3845C116.398 14.4845 116.337 14.5753 116.261 14.6519C116.184 14.7284 116.093 14.7891 115.993 14.8305C115.893 14.8719 115.786 14.8931 115.678 14.8931H114.847V8.10918H115.773C115.932 8.10914 116.087 8.16315 116.212 8.26242C116.337 8.36168 116.424 8.50033 116.46 8.65577C116.881 8.19328 117.428 7.94098 118.06 7.94098ZM122.854 8.09713C123.024 8.09708 123.19 8.1496 123.329 8.2475C123.468 8.34541 123.574 8.48391 123.631 8.64405L125.133 12.8486L126.635 8.64415C126.692 8.48402 126.798 8.34551 126.937 8.2476C127.076 8.1497 127.242 8.09718 127.412 8.09724H128.598L126.152 14.3567C126.091 14.5112 125.986 14.6439 125.849 14.7374C125.711 14.831 125.549 14.881 125.383 14.8809H124.333L121.668 8.09713H122.854Z' fill='%23373F45'/%3E%3Cpath d='M135.085 14.5514C134.566 14.7616 133.513 15.0416 132.418 15.0416C130.496 15.0416 129.024 13.9345 129.024 11.4396C129.024 9.19701 130.451 7.99792 132.191 7.99792C134.338 7.99792 135.254 9.4378 135.158 11.3979C135.139 11.8029 134.786 12.0983 134.38 12.0983H130.679C130.763 13.1916 131.562 13.7662 132.615 13.7662C133.028 13.7662 133.462 13.7452 133.983 13.6481C134.535 13.545 135.085 13.9375 135.085 14.4985V14.5514ZM133.673 10.949C133.785 9.87621 133.061 9.28752 132.191 9.28752C131.321 9.28752 130.734 9.93979 130.679 10.9489L133.673 10.949Z' fill='%23373F45'/%3E%3Cpath d='M137.345 8.11122C137.497 8.11118 137.645 8.16229 137.765 8.25635C137.884 8.35041 137.969 8.48197 138.005 8.62993C138.566 8.20932 139.268 7.94303 139.759 7.94303C139.801 7.94303 140.068 7.94303 140.489 7.99913V8.7265C140.489 9.11748 140.15 9.4147 139.759 9.4147C139.31 9.4147 138.651 9.5829 138.131 9.8773V14.8951H136.462V8.11112L137.345 8.11122ZM156.6 14.0508V8.09104H155.769C155.314 8.09104 154.944 8.45999 154.944 8.9151V14.8748H155.775C156.23 14.8748 156.6 14.5058 156.6 14.0508ZM158.857 12.9447V9.34254H157.749V8.91912C157.749 8.46401 158.118 8.09506 158.574 8.09506H158.857V6.56739L160.499 6.10479V8.09506H161.986V8.51848C161.986 8.97359 161.617 9.34254 161.161 9.34254H160.499V12.7345C160.499 13.2566 160.795 13.44 161.177 13.503C161.626 13.5774 162 13.9024 162 14.3574V14.977C160.446 14.977 158.857 14.9086 158.857 12.9447ZM98.1929 10.1124C98.2033 6.94046 100.598 5.16809 102.895 5.16809C104.171 5.16809 105.342 5.44285 106.304 6.12953L105.914 6.6631C105.654 7.02011 105.16 7.16194 104.749 6.99949C104.169 6.7702 103.622 6.7218 103.215 6.7218C101.335 6.7218 99.9169 7.92849 99.9068 10.1123C99.9169 12.2959 101.335 13.5201 103.215 13.5201C103.622 13.5201 104.169 13.4717 104.749 13.2424C105.16 13.0799 105.654 13.2046 105.914 13.5615L106.304 14.0952C105.342 14.7819 104.171 15.0566 102.895 15.0566C100.598 15.0566 98.2033 13.2842 98.1929 10.1124ZM147.619 5.21768C148.074 5.21768 148.444 5.58663 148.444 6.04174V9.81968L151.82 5.58131C151.897 5.47733 151.997 5.39282 152.112 5.3346C152.227 5.27638 152.355 5.24607 152.484 5.24611H153.984L150.166 10.0615L153.984 14.8749H152.484C152.355 14.8749 152.227 14.8446 152.112 14.7864C151.997 14.7281 151.897 14.6436 151.82 14.5397L148.444 10.3025V14.0508C148.444 14.5059 148.074 14.8749 147.619 14.8749H146.746V5.21768H147.619Z' fill='%23373F45'/%3E%3Cpath d='M0.773438 6.5752H2.68066C3.56543 6.5752 4.2041 6.7041 4.59668 6.96191C4.99219 7.21973 5.18994 7.62695 5.18994 8.18359C5.18994 8.55859 5.09326 8.87061 4.8999 9.11963C4.70654 9.36865 4.42822 9.52539 4.06494 9.58984V9.63379C4.51611 9.71875 4.84717 9.88721 5.05811 10.1392C5.27197 10.3882 5.37891 10.7266 5.37891 11.1543C5.37891 11.7314 5.17676 12.1841 4.77246 12.5122C4.37109 12.8374 3.81152 13 3.09375 13H0.773438V6.5752ZM1.82373 9.22949H2.83447C3.27393 9.22949 3.59473 9.16064 3.79688 9.02295C3.99902 8.88232 4.1001 8.64502 4.1001 8.31104C4.1001 8.00928 3.99023 7.79102 3.77051 7.65625C3.55371 7.52148 3.20801 7.4541 2.7334 7.4541H1.82373V9.22949ZM1.82373 10.082V12.1167H2.93994C3.37939 12.1167 3.71045 12.0332 3.93311 11.8662C4.15869 11.6963 4.27148 11.4297 4.27148 11.0664C4.27148 10.7324 4.15723 10.4849 3.92871 10.3237C3.7002 10.1626 3.35303 10.082 2.88721 10.082H1.82373Z' fill='%23373F45'/%3E%3Cpath d='M13.011 6.5752V10.7324C13.011 11.207 12.9084 11.623 12.7034 11.9805C12.5012 12.335 12.2068 12.6089 11.8201 12.8022C11.4363 12.9927 10.9763 13.0879 10.4402 13.0879C9.6433 13.0879 9.02368 12.877 8.5813 12.4551C8.13892 12.0332 7.91772 11.4531 7.91772 10.7148V6.5752H8.9724V10.6401C8.9724 11.1704 9.09546 11.5615 9.34155 11.8135C9.58765 12.0654 9.96557 12.1914 10.4753 12.1914C11.4656 12.1914 11.9607 11.6714 11.9607 10.6313V6.5752H13.011Z' fill='%23373F45'/%3E%3Cpath d='M15.9146 13V6.5752H16.9649V13H15.9146Z' fill='%23373F45'/%3E%3Cpath d='M19.9255 13V6.5752H20.9758V12.0991H23.696V13H19.9255Z' fill='%23373F45'/%3E%3Cpath d='M28.2828 13H27.2325V7.47607H25.3428V6.5752H30.1724V7.47607H28.2828V13Z' fill='%23373F45'/%3E%3Cpath d='M41.9472 13H40.8046L39.7148 9.16796C39.6679 9.00097 39.6093 8.76074 39.539 8.44727C39.4687 8.13086 39.4262 7.91113 39.4116 7.78809C39.3823 7.97559 39.3339 8.21875 39.2665 8.51758C39.2021 8.81641 39.1479 9.03905 39.1039 9.18554L38.0405 13H36.8979L36.0673 9.7832L35.2236 6.5752H36.2958L37.2143 10.3193C37.3578 10.9199 37.4604 11.4502 37.5219 11.9102C37.5541 11.6611 37.6025 11.3828 37.6669 11.0752C37.7314 10.7676 37.79 10.5186 37.8427 10.3281L38.8886 6.5752H39.9301L41.0024 10.3457C41.1049 10.6943 41.2133 11.2158 41.3276 11.9102C41.3715 11.4912 41.477 10.958 41.644 10.3105L42.558 6.5752H43.6215L41.9472 13Z' fill='%23373F45'/%3E%3Cpath d='M45.7957 13V6.5752H46.846V13H45.7957Z' fill='%23373F45'/%3E%3Cpath d='M52.0258 13H50.9755V7.47607H49.0859V6.5752H53.9155V7.47607H52.0258V13Z' fill='%23373F45'/%3E%3Cpath d='M61.2312 13H60.1765V10.104H57.2146V13H56.1643V6.5752H57.2146V9.20312H60.1765V6.5752H61.2312V13Z' fill='%23373F45'/%3E%3C/svg%3E");
            }

            .formkit-form[data-uid="e309c832a6"] .formkit-powered-by-convertkit:hover,
            .formkit-form[data-uid="e309c832a6"] .formkit-powered-by-convertkit:focus {
                  background-color: #ffffff;
                  -webkit-transform: scale(1.025) perspective(1px);
                  -ms-transform: scale(1.025) perspective(1px);
                  transform: scale(1.025) perspective(1px);
                  opacity: 1;
            }

            .formkit-form[data-uid="e309c832a6"] .formkit-powered-by-convertkit[data-variant="dark"],
            .formkit-form[data-uid="e309c832a6"] .formkit-powered-by-convertkit[data-variant="light"] {
                  background-color: transparent;
                  border-color: transparent;
                  width: 166px;
            }

            .formkit-form[data-uid="e309c832a6"] .formkit-powered-by-convertkit[data-variant="light"] {
                  color: #ffffff;
                  background-image: url("data:image/svg+xml;charset=utf8,%3Csvg width='162' height='20' viewBox='0 0 162 20' fill='none' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath d='M83.0561 15.2457C86.675 15.2457 89.4722 12.5154 89.4722 9.14749C89.4722 5.99211 86.8443 4.06563 85.1038 4.06563C82.6801 4.06563 80.7373 5.76407 80.4605 8.28551C80.4092 8.75244 80.0387 9.14403 79.5686 9.14069C78.7871 9.13509 77.6507 9.12841 76.9314 9.13092C76.6217 9.13199 76.3658 8.88106 76.381 8.57196C76.4895 6.38513 77.2218 4.3404 78.618 2.76974C80.1695 1.02445 82.4289 0 85.1038 0C89.5979 0 93.8406 4.07791 93.8406 9.14749C93.8406 14.7608 89.1832 19.3113 83.1517 19.3113C78.8502 19.3113 74.5179 16.5041 73.0053 12.5795C72.9999 12.565 72.9986 12.5492 73.0015 12.534C73.0218 12.4179 73.0617 12.3118 73.1011 12.2074C73.1583 12.0555 73.2143 11.907 73.2062 11.7359L73.18 11.1892C73.174 11.0569 73.2075 10.9258 73.2764 10.8127C73.3452 10.6995 73.4463 10.6094 73.5666 10.554L73.7852 10.4523C73.9077 10.3957 74.0148 10.3105 74.0976 10.204C74.1803 10.0974 74.2363 9.97252 74.2608 9.83983C74.3341 9.43894 74.6865 9.14749 75.0979 9.14749C75.7404 9.14749 76.299 9.57412 76.5088 10.1806C77.5188 13.1 79.1245 15.2457 83.0561 15.2457Z' fill='white'/%3E%3Cpath d='M155.758 6.91365C155.028 6.91365 154.804 6.47916 154.804 5.98857C154.804 5.46997 154.986 5.06348 155.758 5.06348C156.53 5.06348 156.712 5.46997 156.712 5.98857C156.712 6.47905 156.516 6.91365 155.758 6.91365ZM142.441 12.9304V9.32833L141.415 9.32323V8.90392C141.415 8.44719 141.786 8.07758 142.244 8.07986L142.441 8.08095V6.55306L144.082 6.09057V8.08073H145.569V8.50416C145.569 8.61242 145.548 8.71961 145.506 8.81961C145.465 8.91961 145.404 9.01047 145.328 9.08699C145.251 9.16351 145.16 9.2242 145.06 9.26559C144.96 9.30698 144.853 9.32826 144.745 9.32822H144.082V12.7201C144.082 13.2423 144.378 13.4256 144.76 13.4887C145.209 13.5629 145.583 13.888 145.583 14.343V14.9626C144.029 14.9626 142.441 14.8942 142.441 12.9304Z' fill='white'/%3E%3Cpath d='M110.058 7.92554C108.417 7.88344 106.396 8.92062 106.396 11.5137C106.396 14.0646 108.417 15.0738 110.058 15.0318C111.742 15.0738 113.748 14.0646 113.748 11.5137C113.748 8.92062 111.742 7.88344 110.058 7.92554ZM110.07 13.7586C108.878 13.7586 108.032 12.8905 108.032 11.461C108.032 10.1013 108.878 9.20569 110.071 9.20569C111.263 9.20569 112.101 10.0995 112.101 11.459C112.101 12.8887 111.263 13.7586 110.07 13.7586Z' fill='white'/%3E%3Cpath d='M118.06 7.94098C119.491 7.94098 120.978 8.33337 120.978 11.1366V14.893H120.063C119.608 14.893 119.238 14.524 119.238 14.0689V10.9965C119.238 9.66506 118.747 9.16047 117.891 9.16047C117.414 9.16047 116.797 9.52486 116.502 9.81915V14.069C116.502 14.1773 116.481 14.2845 116.44 14.3845C116.398 14.4845 116.337 14.5753 116.261 14.6519C116.184 14.7284 116.093 14.7891 115.993 14.8305C115.893 14.8719 115.786 14.8931 115.678 14.8931H114.847V8.10918H115.773C115.932 8.10914 116.087 8.16315 116.212 8.26242C116.337 8.36168 116.424 8.50033 116.46 8.65577C116.881 8.19328 117.428 7.94098 118.06 7.94098ZM122.854 8.09713C123.024 8.09708 123.19 8.1496 123.329 8.2475C123.468 8.34541 123.574 8.48391 123.631 8.64405L125.133 12.8486L126.635 8.64415C126.692 8.48402 126.798 8.34551 126.937 8.2476C127.076 8.1497 127.242 8.09718 127.412 8.09724H128.598L126.152 14.3567C126.091 14.5112 125.986 14.6439 125.849 14.7374C125.711 14.831 125.549 14.881 125.383 14.8809H124.333L121.668 8.09713H122.854Z' fill='white'/%3E%3Cpath d='M135.085 14.5514C134.566 14.7616 133.513 15.0416 132.418 15.0416C130.496 15.0416 129.024 13.9345 129.024 11.4396C129.024 9.19701 130.451 7.99792 132.191 7.99792C134.338 7.99792 135.254 9.4378 135.158 11.3979C135.139 11.8029 134.786 12.0983 134.38 12.0983H130.679C130.763 13.1916 131.562 13.7662 132.615 13.7662C133.028 13.7662 133.462 13.7452 133.983 13.6481C134.535 13.545 135.085 13.9375 135.085 14.4985V14.5514ZM133.673 10.949C133.785 9.87621 133.061 9.28752 132.191 9.28752C131.321 9.28752 130.734 9.93979 130.679 10.9489L133.673 10.949Z' fill='white'/%3E%3Cpath d='M137.345 8.11122C137.497 8.11118 137.645 8.16229 137.765 8.25635C137.884 8.35041 137.969 8.48197 138.005 8.62993C138.566 8.20932 139.268 7.94303 139.759 7.94303C139.801 7.94303 140.068 7.94303 140.489 7.99913V8.7265C140.489 9.11748 140.15 9.4147 139.759 9.4147C139.31 9.4147 138.651 9.5829 138.131 9.8773V14.8951H136.462V8.11112L137.345 8.11122ZM156.6 14.0508V8.09104H155.769C155.314 8.09104 154.944 8.45999 154.944 8.9151V14.8748H155.775C156.23 14.8748 156.6 14.5058 156.6 14.0508ZM158.857 12.9447V9.34254H157.749V8.91912C157.749 8.46401 158.118 8.09506 158.574 8.09506H158.857V6.56739L160.499 6.10479V8.09506H161.986V8.51848C161.986 8.97359 161.617 9.34254 161.161 9.34254H160.499V12.7345C160.499 13.2566 160.795 13.44 161.177 13.503C161.626 13.5774 162 13.9024 162 14.3574V14.977C160.446 14.977 158.857 14.9086 158.857 12.9447ZM98.1929 10.1124C98.2033 6.94046 100.598 5.16809 102.895 5.16809C104.171 5.16809 105.342 5.44285 106.304 6.12953L105.914 6.6631C105.654 7.02011 105.16 7.16194 104.749 6.99949C104.169 6.7702 103.622 6.7218 103.215 6.7218C101.335 6.7218 99.9169 7.92849 99.9068 10.1123C99.9169 12.2959 101.335 13.5201 103.215 13.5201C103.622 13.5201 104.169 13.4717 104.749 13.2424C105.16 13.0799 105.654 13.2046 105.914 13.5615L106.304 14.0952C105.342 14.7819 104.171 15.0566 102.895 15.0566C100.598 15.0566 98.2033 13.2842 98.1929 10.1124ZM147.619 5.21768C148.074 5.21768 148.444 5.58663 148.444 6.04174V9.81968L151.82 5.58131C151.897 5.47733 151.997 5.39282 152.112 5.3346C152.227 5.27638 152.355 5.24607 152.484 5.24611H153.984L150.166 10.0615L153.984 14.8749H152.484C152.355 14.8749 152.227 14.8446 152.112 14.7864C151.997 14.7281 151.897 14.6436 151.82 14.5397L148.444 10.3025V14.0508C148.444 14.5059 148.074 14.8749 147.619 14.8749H146.746V5.21768H147.619Z' fill='white'/%3E%3Cpath d='M0.773438 6.5752H2.68066C3.56543 6.5752 4.2041 6.7041 4.59668 6.96191C4.99219 7.21973 5.18994 7.62695 5.18994 8.18359C5.18994 8.55859 5.09326 8.87061 4.8999 9.11963C4.70654 9.36865 4.42822 9.52539 4.06494 9.58984V9.63379C4.51611 9.71875 4.84717 9.88721 5.05811 10.1392C5.27197 10.3882 5.37891 10.7266 5.37891 11.1543C5.37891 11.7314 5.17676 12.1841 4.77246 12.5122C4.37109 12.8374 3.81152 13 3.09375 13H0.773438V6.5752ZM1.82373 9.22949H2.83447C3.27393 9.22949 3.59473 9.16064 3.79688 9.02295C3.99902 8.88232 4.1001 8.64502 4.1001 8.31104C4.1001 8.00928 3.99023 7.79102 3.77051 7.65625C3.55371 7.52148 3.20801 7.4541 2.7334 7.4541H1.82373V9.22949ZM1.82373 10.082V12.1167H2.93994C3.37939 12.1167 3.71045 12.0332 3.93311 11.8662C4.15869 11.6963 4.27148 11.4297 4.27148 11.0664C4.27148 10.7324 4.15723 10.4849 3.92871 10.3237C3.7002 10.1626 3.35303 10.082 2.88721 10.082H1.82373Z' fill='white'/%3E%3Cpath d='M13.011 6.5752V10.7324C13.011 11.207 12.9084 11.623 12.7034 11.9805C12.5012 12.335 12.2068 12.6089 11.8201 12.8022C11.4363 12.9927 10.9763 13.0879 10.4402 13.0879C9.6433 13.0879 9.02368 12.877 8.5813 12.4551C8.13892 12.0332 7.91772 11.4531 7.91772 10.7148V6.5752H8.9724V10.6401C8.9724 11.1704 9.09546 11.5615 9.34155 11.8135C9.58765 12.0654 9.96557 12.1914 10.4753 12.1914C11.4656 12.1914 11.9607 11.6714 11.9607 10.6313V6.5752H13.011Z' fill='white'/%3E%3Cpath d='M15.9146 13V6.5752H16.9649V13H15.9146Z' fill='white'/%3E%3Cpath d='M19.9255 13V6.5752H20.9758V12.0991H23.696V13H19.9255Z' fill='white'/%3E%3Cpath d='M28.2828 13H27.2325V7.47607H25.3428V6.5752H30.1724V7.47607H28.2828V13Z' fill='white'/%3E%3Cpath d='M41.9472 13H40.8046L39.7148 9.16796C39.6679 9.00097 39.6093 8.76074 39.539 8.44727C39.4687 8.13086 39.4262 7.91113 39.4116 7.78809C39.3823 7.97559 39.3339 8.21875 39.2665 8.51758C39.2021 8.81641 39.1479 9.03905 39.1039 9.18554L38.0405 13H36.8979L36.0673 9.7832L35.2236 6.5752H36.2958L37.2143 10.3193C37.3578 10.9199 37.4604 11.4502 37.5219 11.9102C37.5541 11.6611 37.6025 11.3828 37.6669 11.0752C37.7314 10.7676 37.79 10.5186 37.8427 10.3281L38.8886 6.5752H39.9301L41.0024 10.3457C41.1049 10.6943 41.2133 11.2158 41.3276 11.9102C41.3715 11.4912 41.477 10.958 41.644 10.3105L42.558 6.5752H43.6215L41.9472 13Z' fill='white'/%3E%3Cpath d='M45.7957 13V6.5752H46.846V13H45.7957Z' fill='white'/%3E%3Cpath d='M52.0258 13H50.9755V7.47607H49.0859V6.5752H53.9155V7.47607H52.0258V13Z' fill='white'/%3E%3Cpath d='M61.2312 13H60.1765V10.104H57.2146V13H56.1643V6.5752H57.2146V9.20312H60.1765V6.5752H61.2312V13Z' fill='white'/%3E%3C/svg%3E");
            }

            @-webkit-keyframes formkit-bouncedelay-formkit-form-data-uid-e309c832a6- {

                  0%,
                  80%,
                  100% {
                        -webkit-transform: scale(0);
                        -ms-transform: scale(0);
                        transform: scale(0);
                  }

                  40% {
                        -webkit-transform: scale(1);
                        -ms-transform: scale(1);
                        transform: scale(1);
                  }
            }

            @keyframes formkit-bouncedelay-formkit-form-data-uid-e309c832a6- {

                  0%,
                  80%,
                  100% {
                        -webkit-transform: scale(0);
                        -ms-transform: scale(0);
                        transform: scale(0);
                  }

                  40% {
                        -webkit-transform: scale(1);
                        -ms-transform: scale(1);
                        transform: scale(1);
                  }
            }

            .formkit-form[data-uid="e309c832a6"] blockquote {
                  padding: 10px 20px;
                  margin: 0 0 20px;
                  border-left: 5px solid #e1e1e1;
            }

            .formkit-form[data-uid="e309c832a6"] .seva-custom-content {
                  padding: 15px;
                  font-size: 16px;
                  color: #fff;
                  mix-blend-mode: difference;
            }

            .formkit-form[data-uid="e309c832a6"] .formkit-modal.guard {
                  max-width: 420px;
                  width: 100%;
            }

            .formkit-form[data-uid="e309c832a6"] {
                  border: 1px solid #e3e3e3;
                  max-width: 700px;
                  position: relative;
                  overflow: hidden;
            }

            .formkit-form[data-uid="e309c832a6"] .formkit-background {
                  width: 100%;
                  height: 100%;
                  position: absolute;
                  top: 0;
                  left: 0;
                  background-size: cover;
                  background-position: center;
                  opacity: 0.3;
            }

            .formkit-form[data-uid="e309c832a6"] [data-style="minimal"] {
                  padding: 20px;
                  width: 100%;
                  position: relative;
            }

            .formkit-form[data-uid="e309c832a6"] .formkit-header {
                  margin: 0 0 27px 0;
                  text-align: center;
            }

            .formkit-form[data-uid="e309c832a6"] .formkit-subheader {
                  margin: 18px 0;
                  text-align: center;
            }

            .formkit-form[data-uid="e309c832a6"] .formkit-guarantee {
                  font-size: 13px;
                  margin: 10px 0 15px 0;
                  text-align: center;
            }

            .formkit-form[data-uid="e309c832a6"] .formkit-guarantee>p {
                  margin: 0;
            }

            .formkit-form[data-uid="e309c832a6"] .formkit-powered-by-convertkit-container {
                  margin-bottom: 0;
            }

            .formkit-form[data-uid="e309c832a6"] .formkit-fields {
                  display: -webkit-box;
                  display: -webkit-flex;
                  display: -ms-flexbox;
                  display: flex;
                  -webkit-flex-wrap: wrap;
                  -ms-flex-wrap: wrap;
                  flex-wrap: wrap;
                  margin: 25px auto 0 auto;
            }

            .formkit-form[data-uid="e309c832a6"] .formkit-field {
                  min-width: 220px;
            }

            .formkit-form[data-uid="e309c832a6"] .formkit-field,
            .formkit-form[data-uid="e309c832a6"] .formkit-submit {
                  margin: 0 0 15px 0;
                  -webkit-flex: 1 0 100%;
                  -ms-flex: 1 0 100%;
                  flex: 1 0 100%;
            }

            .formkit-form[data-uid="e309c832a6"][min-width~="600"] [data-style="minimal"] {
                  padding: 40px;
            }

            .formkit-form[data-uid="e309c832a6"][min-width~="600"] .formkit-fields[data-stacked="false"] {
                  margin-left: -5px;
                  margin-right: -5px;
            }

            .formkit-form[data-uid="e309c832a6"][min-width~="600"] .formkit-fields[data-stacked="false"] .formkit-field,
            .formkit-form[data-uid="e309c832a6"][min-width~="600"] .formkit-fields[data-stacked="false"] .formkit-submit {
                  margin: 0 5px 15px 5px;
            }

            .formkit-form[data-uid="e309c832a6"][min-width~="600"] .formkit-fields[data-stacked="false"] .formkit-field {
                  -webkit-flex: 100 1 auto;
                  -ms-flex: 100 1 auto;
                  flex: 100 1 auto;
            }

            .formkit-form[data-uid="e309c832a6"][min-width~="600"] .formkit-fields[data-stacked="false"] .formkit-submit {
                  -webkit-flex: 1 1 auto;
                  -ms-flex: 1 1 auto;
                  flex: 1 1 auto;
            }
      </style>
</form>

		<div class="sponsor">
        <div class="sponsor-avatar"></div><p class="sponsor-bio"><em>Did you find this article helpful?</em></p><div class="sponsor-custom"><script type="text/javascript" src="https://cdnjs.buymeacoffee.com/1.0.0/button.prod.min.js" data-name="bmc-button" data-slug="reachsumit" data-color="#FFDD00" data-emoji=""  data-font="Cookie" data-text="Buy me a coffee" data-outline-color="#000000" data-font-color="#000000" data-coffee-color="#ffffff" ></script></div></div><div class="post-footer" id="post-footer">
    <div class="post-info">
        <div class="post-info-line">
            <div class="post-info-mod">
                <span>Updated on 2020-12-07</span>
            </div>
            <div class="post-info-license"></div>
        </div>
        <div class="post-info-line">
            <div class="post-info-md"></div>
            <div class="post-info-share">
                <span><a href="#" title="Share on Twitter" data-sharer="twitter" data-url="https://blog.reachsumit.com/posts/2020/12/generating-empathetic-responses/" data-title="Towards Empathetic Dialogue Systems" data-via="_reachsumit" data-hashtags="dialogue systems,literature review"><i class="fab fa-twitter fa-fw"></i></a><a href="#" title="Share on Facebook" data-sharer="facebook" data-url="https://blog.reachsumit.com/posts/2020/12/generating-empathetic-responses/" data-hashtag="dialogue systems"><i class="fab fa-facebook-square fa-fw"></i></a><a href="#" title="Share on Linkedin" data-sharer="linkedin" data-url="https://blog.reachsumit.com/posts/2020/12/generating-empathetic-responses/"><i class="fab fa-linkedin fa-fw"></i></a><a href="#" title="Share on WhatsApp" data-sharer="whatsapp" data-url="https://blog.reachsumit.com/posts/2020/12/generating-empathetic-responses/" data-title="Towards Empathetic Dialogue Systems" data-web><i class="fab fa-whatsapp fa-fw"></i></a><a href="#" title="Share on Hacker News" data-sharer="hackernews" data-url="https://blog.reachsumit.com/posts/2020/12/generating-empathetic-responses/" data-title="Towards Empathetic Dialogue Systems"><i class="fab fa-hacker-news fa-fw"></i></a><a href="#" title="Share on Reddit" data-sharer="reddit" data-url="https://blog.reachsumit.com/posts/2020/12/generating-empathetic-responses/"><i class="fab fa-reddit fa-fw"></i></a><a href="#" title="Share on Line" data-sharer="line" data-url="https://blog.reachsumit.com/posts/2020/12/generating-empathetic-responses/" data-title="Towards Empathetic Dialogue Systems"><i data-svg-src="https://cdn.jsdelivr.net/npm/simple-icons@v5.21.1/icons/line.svg"></i></a><a href="#" title="Share on Pocket" data-sharer="pocket" data-url="https://blog.reachsumit.com/posts/2020/12/generating-empathetic-responses/"><i class="fab fa-get-pocket fa-fw"></i></a><a href="#" title="Share on 微博" data-sharer="weibo" data-url="https://blog.reachsumit.com/posts/2020/12/generating-empathetic-responses/" data-title="Towards Empathetic Dialogue Systems" data-image="featured-image.webp"><i class="fab fa-weibo fa-fw"></i></a><a href="#" title="Share on Evernote" data-sharer="evernote" data-url="https://blog.reachsumit.com/posts/2020/12/generating-empathetic-responses/" data-title="Towards Empathetic Dialogue Systems"><i class="fab fa-evernote fa-fw"></i></a><a href="#" title="Share on Trello" data-sharer="trello" data-url="https://blog.reachsumit.com/posts/2020/12/generating-empathetic-responses/" data-title="Towards Empathetic Dialogue Systems" data-description="Recognizing feelings in the conversation partner and replying empathetically is a trivial skill for humans. But how can we infuse empathy into responses generated by a conversational dialogue agent or any of the text generation algorithm in Natural Language Processing? In this article, I will describe what empathy means through the lens of various academic disciplines and then do an in-depth review of the prior and current state-of-the-art NLU systems that can simulate empathy."><i class="fab fa-trello fa-fw"></i></a></span>
            </div>
        </div>
    </div>

    <div class="post-info-more">
        <section class="post-tags"><i class="fas fa-tags fa-fw"></i>&nbsp;<a href="/tags/dialogue-systems/">dialogue systems</a>,&nbsp;<a href="/tags/literature-review/">literature review</a></section>
        <section>
            <span><a href="javascript:void(0);" onclick="window.history.back();">Back</a></span>&nbsp;|&nbsp;<span><a href="/">Home</a></span>
        </section>
    </div>

    <div class="post-nav"><a href="/posts/2020/10/leetcode-sliding-window/" class="prev" rel="prev" title="Effective LeetCode: Understanding the Sliding Window Pattern"><i class="fas fa-angle-left fa-fw"></i>Effective LeetCode: Understanding the Sliding Window Pattern</a>
            <a href="/posts/2022/06/sql-nosql-newsql/" class="next" rel="next" title="SQL vs NoSQL vs NewSQL: An In-depth Literature Review">SQL vs NoSQL vs NewSQL: An In-depth Literature Review<i class="fas fa-angle-right fa-fw"></i></a></div>
</div>
<div id="comments"><div id="disqus_thread" class="comment"></div><noscript>
                Please enable JavaScript to view the comments powered by <a href="https://disqus.com/?ref_noscript">Disqus</a>.
            </noscript></div></article></div>
        </main><footer class="footer">
        <div class="footer-container"><div class="footer-line"><i class="far fa-copyright fa-fw"></i><span itemprop="copyrightYear">2020 - 2023</span><span class="author" itemprop="copyrightHolder">&nbsp;<a href="https://reachsumit.com" target="_blank" rel="noopener noreferrer">Sumit Kumar</a></span>&nbsp;|&nbsp;<span class="license"><a rel="license external nofollow noopener noreffer" href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank">CC BY-NC 4.0</a></span></div>
            <div class="footer-line"></div>
            <div class="footer-line">
            </div>
        </div></footer></div>

    <div id="fixed-buttons"><a href="#back-to-top" id="back-to-top-button" class="fixed-button" title="Back to Top">
            <i class="fas fa-arrow-up fa-fw"></i>
        </a><a href="#" id="view-comments" class="fixed-button" title="View Comments">
            <i class="fas fa-comment fa-fw"></i>
        </a>
    </div><div class="assets"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css"><link rel="preload" as="style" onload="this.onload=null;this.rel='stylesheet'" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/copy-tex.min.css">
        <noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/copy-tex.min.css"></noscript><link rel="stylesheet" href="/css/071124.min.css"><script type="text/javascript">window.config={"code":{"copyTitle":"Copy to clipboard","maxShownLines":10},"comment":{},"data":{"desktop-header-typeit":"Sumit's Diary","mobile-header-typeit":"Sumit's Diary"},"math":{"delimiters":[{"display":true,"left":"$$","right":"$$"},{"display":true,"left":"\\[","right":"\\]"},{"display":false,"left":"$","right":"$"},{"display":false,"left":"\\(","right":"\\)"}],"strict":false},"search":{"algoliaAppID":"LV11CUNTAX","algoliaIndex":"blog_reachsumit","algoliaSearchKey":"98d868016771f8a06b967e7eb3eaf63a","highlightTag":"em","maxResultLength":10,"noResultsFound":"No results found","snippetLength":30,"type":"algolia"},"sharerjs":true,"table":{"sort":true},"typeit":{"cursorChar":"|","cursorSpeed":1000,"data":{"desktop-header-typeit":["desktop-header-typeit"],"mobile-header-typeit":["mobile-header-typeit"]},"duration":2700,"speed":100}};</script><script type="text/javascript" src="https://reachsumit-blog.disqus.com/embed.js" defer></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/tablesort@5.3.0/src/tablesort.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/clipboard@2.0.8/dist/clipboard.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/sharer.js@0.4.2/sharer.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/typeit@7.0.4/dist/typeit.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js" defer></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js" defer></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/copy-tex.min.js" defer></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/mhchem.min.js" defer></script><script type="text/javascript" src="/js/katex.min.js" defer></script><script type="text/javascript" src="/js/theme.min.js" defer></script><script type="text/javascript">
            window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments);}gtag('js', new Date());
            gtag('config', 'UA-171612692-1');
        </script><script type="text/javascript" src="https://www.googletagmanager.com/gtag/js?id=UA-171612692-1" async></script></div>
</body>

</html>