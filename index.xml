<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>Sumit&#39;s Diary</title>
        <link>https://blog.reachsumit.com/</link>
        <description>Welcome to Sumit Kumar&#39;s Personal Blog!</description>
        <generator>Hugo -- gohugo.io</generator><language>en</language><managingEditor>hello@reachsumit.com (Sumit Kumar)</managingEditor>
            <webMaster>hello@reachsumit.com (Sumit Kumar)</webMaster><lastBuildDate>Mon, 01 Sep 2025 00:00:00 &#43;0000</lastBuildDate>
            <atom:link href="https://blog.reachsumit.com/index.xml" rel="self" type="application/rss+xml" />
        <item>
    <title>Embedding Collapse in Recommender Systems: Causes, Consequences, and Solutions</title>
    <link>https://blog.reachsumit.com/posts/2024/11/embedding-collapse-recsys/</link>
    <pubDate>Wed, 06 Nov 2024 00:00:00 &#43;0000</pubDate><author>
        <name>Sumit Kumar</name>
    </author><guid>https://blog.reachsumit.com/posts/2024/11/embedding-collapse-recsys/</guid>
    <description><![CDATA[<div class="featured-image">
                <img src="/posts/2024/11/embedding-collapse-recsys/featured-image-preview.webp" referrerpolicy="no-referrer">
            </div>Learned embeddings often suffer from &rsquo;embedding collapse&rsquo;, where they occupy only a small subspace of the available dimensions. This article explores the causes of embedding collapse, from two-tower models to GNN-based systems, and its impact on model scalability and recommendation quality. We discuss methods to detect collapse and examine recent solutions proposed by research teams at Visa, Facebook AI, and Tencent Ads to address this challenge.]]></description>
</item><item>
    <title>Incorporating Ads into Large Language Models Outputs</title>
    <link>https://blog.reachsumit.com/posts/2024/08/ads-llm/</link>
    <pubDate>Sun, 11 Aug 2024 00:00:00 &#43;0000</pubDate><author>
        <name>Sumit Kumar</name>
    </author><guid>https://blog.reachsumit.com/posts/2024/08/ads-llm/</guid>
    <description><![CDATA[<div class="featured-image">
                <img src="/posts/2024/08/ads-llm/featured-image-preview.webp" referrerpolicy="no-referrer">
            </div>This article provides an introduction to online advertising systems and explores research work that incorporates ads into the LLM responses to user queries of commercial nature.]]></description>
</item><item>
    <title>The Evolution of Multi-task Learning Based Video Recommender Systems - Part 2</title>
    <link>https://blog.reachsumit.com/posts/2024/06/multi-task-video-recsys-p2/</link>
    <pubDate>Sat, 22 Jun 2024 00:00:00 &#43;0000</pubDate><author>
        <name>Sumit Kumar</name>
    </author><guid>https://blog.reachsumit.com/posts/2024/06/multi-task-video-recsys-p2/</guid>
    <description><![CDATA[<div class="featured-image">
                <img src="/posts/2024/06/multi-task-video-recsys-p2/featured-image-preview.webp" referrerpolicy="no-referrer">
            </div>This article continues the discussion on the evolution of multi-task learning-based large-scale recommender systems. We take a look at strategies from Kuaishou, Tencent, YouTube, Facebook, and Amazon Prime Video to disentangle input space and address systematic biases. The article ends with sharing several tips and learnings for professionals working in this domain.]]></description>
</item><item>
    <title>The Evolution of Multi-task Learning Based Video Recommender Systems - Part 1</title>
    <link>https://blog.reachsumit.com/posts/2024/06/multi-task-video-recsys-p1/</link>
    <pubDate>Sun, 16 Jun 2024 00:00:00 &#43;0000</pubDate><author>
        <name>Sumit Kumar</name>
    </author><guid>https://blog.reachsumit.com/posts/2024/06/multi-task-video-recsys-p1/</guid>
    <description><![CDATA[<div class="featured-image">
                <img src="/posts/2024/06/multi-task-video-recsys-p1/featured-image-preview.webp" referrerpolicy="no-referrer">
            </div>This article introduces the multi-task learning paradigm adopted by various large-scale video recommender systems. It introduces a general setup for such an MTL-based recommender. It highlights several associated challenges and describes solutions adopted by various state-of-the-art recommenders in the industry.]]></description>
</item><item>
    <title>An Introduction to Multi-Task Learning based Recommender Systems</title>
    <link>https://blog.reachsumit.com/posts/2024/01/multi-task-learning-recsys/</link>
    <pubDate>Fri, 26 Jan 2024 00:00:00 &#43;0000</pubDate><author>
        <name>Sumit Kumar</name>
    </author><guid>https://blog.reachsumit.com/posts/2024/01/multi-task-learning-recsys/</guid>
    <description><![CDATA[<div class="featured-image">
                <img src="/posts/2024/01/multi-task-learning-recsys/featured-image-preview.webp" referrerpolicy="no-referrer">
            </div>This article provides an introduction and literature review for multi-task learning based recommender systems. We learn how to discover task relations, design MTL architectures and overcome some of the associated challenges.]]></description>
</item><item>
    <title>A Guide to User Behavior Modeling</title>
    <link>https://blog.reachsumit.com/posts/2024/01/user-behavior-modeling-recsys/</link>
    <pubDate>Sun, 07 Jan 2024 00:00:00 &#43;0000</pubDate><author>
        <name>Sumit Kumar</name>
    </author><guid>https://blog.reachsumit.com/posts/2024/01/user-behavior-modeling-recsys/</guid>
    <description><![CDATA[<div class="featured-image">
                <img src="/posts/2024/01/user-behavior-modeling-recsys/featured-image-preview.webp" referrerpolicy="no-referrer">
            </div>Modeling users&rsquo; past historical interactions or behavior sequences is an essential task for domains like recommender systems, click-through rate prediction, targeted advertisement, and more. This article provides a comprehensive introduction to the user behavior modeling paradigm along with highlighting several relevant and recent research works.]]></description>
</item><item>
    <title>Strategies for Effective and Efficient Text Ranking Using Large Language Models</title>
    <link>https://blog.reachsumit.com/posts/2023/12/towards-ranking-aware-llms/</link>
    <pubDate>Tue, 26 Dec 2023 00:00:00 &#43;0000</pubDate><author>
        <name>Sumit Kumar</name>
    </author><guid>https://blog.reachsumit.com/posts/2023/12/towards-ranking-aware-llms/</guid>
    <description><![CDATA[<div class="featured-image">
                <img src="/posts/2023/12/towards-ranking-aware-llms/featured-image-preview.webp" referrerpolicy="no-referrer">
            </div>The previous article did a deep dive into the prompting-based pointwise, pairwise, and listwise techniques that directly use LLMs to perform reranking. In this article, we will take a closer look at some of the shortcomings of the prompting methods and explore the latest efforts to train ranking-aware LLMs. The article also describes several strategies to build effective and efficient LLM-based rerankers.]]></description>
</item><item>
    <title>Prompting-based Methods for Text Ranking Using Large Language Models</title>
    <link>https://blog.reachsumit.com/posts/2023/12/prompting-llm-for-ranking/</link>
    <pubDate>Wed, 20 Dec 2023 00:00:00 &#43;0000</pubDate><author>
        <name>Sumit Kumar</name>
    </author><guid>https://blog.reachsumit.com/posts/2023/12/prompting-llm-for-ranking/</guid>
    <description><![CDATA[<div class="featured-image">
                <img src="/posts/2023/12/prompting-llm-for-ranking/featured-image-preview.webp" referrerpolicy="no-referrer">
            </div>Large Language Models (LLMs) have demonstrated impressive zero-shot performance on a wide variety of NLP tasks. Recently, there has been a growing interest in applying LLMs to zero-shot text ranking. This article describes a recent paradigm that uses prompting-based approaches to directly utilize LLMs as rerankers in a multi-stage ranking pipeline.]]></description>
</item><item>
    <title>Generative Retrieval for End-to-End Search Systems</title>
    <link>https://blog.reachsumit.com/posts/2023/09/generative-retrieval/</link>
    <pubDate>Wed, 06 Sep 2023 00:00:00 &#43;0000</pubDate><author>
        <name>Sumit Kumar</name>
    </author><guid>https://blog.reachsumit.com/posts/2023/09/generative-retrieval/</guid>
    <description><![CDATA[<div class="featured-image">
                <img src="/posts/2023/09/generative-retrieval/featured-image-preview.webp" referrerpolicy="no-referrer">
            </div>Auto-regressive search engines emerge as a promising paradigm for next-gen information retrieval systems. This article introduces this generative retrieval and the various latest techniques that have been proposed to improve its effectiveness.]]></description>
</item><item>
    <title>Representing Users and Items in Large Language Models based Recommender Systems</title>
    <link>https://blog.reachsumit.com/posts/2023/06/llms-for-recsys-entity-representation/</link>
    <pubDate>Sun, 18 Jun 2023 00:00:00 &#43;0000</pubDate><author>
        <name>Sumit Kumar</name>
    </author><guid>https://blog.reachsumit.com/posts/2023/06/llms-for-recsys-entity-representation/</guid>
    <description><![CDATA[<div class="featured-image">
                <img src="/posts/2023/06/llms-for-recsys-entity-representation/featured-image-preview.webp" referrerpolicy="no-referrer">
            </div>Large Language Models (LLMs) have emerged as viable tools for various recommendation tasks. This article highlights various methods for incorporating users, items, and behavior data into the instructions for LLMs.]]></description>
</item></channel>
</rss>
