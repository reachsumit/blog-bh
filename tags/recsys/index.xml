<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>Recsys - Tag - Sumit&#39;s Diary</title>
        <link>https://blog.reachsumit.com/tags/recsys/</link>
        <description>Recsys - Tag - Sumit&#39;s Diary</description>
        <generator>Hugo -- gohugo.io</generator><language>en</language><managingEditor>hello@reachsumit.com (Sumit Kumar)</managingEditor>
            <webMaster>hello@reachsumit.com (Sumit Kumar)</webMaster><lastBuildDate>Wed, 06 Nov 2024 00:00:00 &#43;0000</lastBuildDate><atom:link href="https://blog.reachsumit.com/tags/recsys/" rel="self" type="application/rss+xml" /><item>
    <title>Embedding Collapse in Recommender Systems: Causes, Consequences, and Solutions</title>
    <link>https://blog.reachsumit.com/posts/2024/11/embedding-collapse-recsys/</link>
    <pubDate>Wed, 06 Nov 2024 00:00:00 &#43;0000</pubDate><author>
        <name>Sumit Kumar</name>
    </author><guid>https://blog.reachsumit.com/posts/2024/11/embedding-collapse-recsys/</guid>
    <description><![CDATA[<div class="featured-image">
                <img src="/posts/2024/11/embedding-collapse-recsys/featured-image-preview.webp" referrerpolicy="no-referrer">
            </div>Learned embeddings often suffer from &rsquo;embedding collapse&rsquo;, where they occupy only a small subspace of the available dimensions. This article explores the causes of embedding collapse, from two-tower models to GNN-based systems, and its impact on model scalability and recommendation quality. We discuss methods to detect collapse and examine recent solutions proposed by research teams at Visa, Facebook AI, and Tencent Ads to address this challenge.]]></description>
</item><item>
    <title>The Evolution of Multi-task Learning Based Video Recommender Systems - Part 2</title>
    <link>https://blog.reachsumit.com/posts/2024/06/multi-task-video-recsys-p2/</link>
    <pubDate>Sat, 22 Jun 2024 00:00:00 &#43;0000</pubDate><author>
        <name>Sumit Kumar</name>
    </author><guid>https://blog.reachsumit.com/posts/2024/06/multi-task-video-recsys-p2/</guid>
    <description><![CDATA[<div class="featured-image">
                <img src="/posts/2024/06/multi-task-video-recsys-p2/featured-image-preview.webp" referrerpolicy="no-referrer">
            </div>This article continues the discussion on the evolution of multi-task learning-based large-scale recommender systems. We take a look at strategies from Kuaishou, Tencent, YouTube, Facebook, and Amazon Prime Video to disentangle input space and address systematic biases. The article ends with sharing several tips and learnings for professionals working in this domain.]]></description>
</item><item>
    <title>The Evolution of Multi-task Learning Based Video Recommender Systems - Part 1</title>
    <link>https://blog.reachsumit.com/posts/2024/06/multi-task-video-recsys-p1/</link>
    <pubDate>Sun, 16 Jun 2024 00:00:00 &#43;0000</pubDate><author>
        <name>Sumit Kumar</name>
    </author><guid>https://blog.reachsumit.com/posts/2024/06/multi-task-video-recsys-p1/</guid>
    <description><![CDATA[<div class="featured-image">
                <img src="/posts/2024/06/multi-task-video-recsys-p1/featured-image-preview.webp" referrerpolicy="no-referrer">
            </div>This article introduces the multi-task learning paradigm adopted by various large-scale video recommender systems. It introduces a general setup for such an MTL-based recommender. It highlights several associated challenges and describes solutions adopted by various state-of-the-art recommenders in the industry.]]></description>
</item><item>
    <title>An Introduction to Multi-Task Learning based Recommender Systems</title>
    <link>https://blog.reachsumit.com/posts/2024/01/multi-task-learning-recsys/</link>
    <pubDate>Fri, 26 Jan 2024 00:00:00 &#43;0000</pubDate><author>
        <name>Sumit Kumar</name>
    </author><guid>https://blog.reachsumit.com/posts/2024/01/multi-task-learning-recsys/</guid>
    <description><![CDATA[<div class="featured-image">
                <img src="/posts/2024/01/multi-task-learning-recsys/featured-image-preview.webp" referrerpolicy="no-referrer">
            </div>This article provides an introduction and literature review for multi-task learning based recommender systems. We learn how to discover task relations, design MTL architectures and overcome some of the associated challenges.]]></description>
</item><item>
    <title>A Guide to User Behavior Modeling</title>
    <link>https://blog.reachsumit.com/posts/2024/01/user-behavior-modeling-recsys/</link>
    <pubDate>Sun, 07 Jan 2024 00:00:00 &#43;0000</pubDate><author>
        <name>Sumit Kumar</name>
    </author><guid>https://blog.reachsumit.com/posts/2024/01/user-behavior-modeling-recsys/</guid>
    <description><![CDATA[<div class="featured-image">
                <img src="/posts/2024/01/user-behavior-modeling-recsys/featured-image-preview.webp" referrerpolicy="no-referrer">
            </div>Modeling users&rsquo; past historical interactions or behavior sequences is an essential task for domains like recommender systems, click-through rate prediction, targeted advertisement, and more. This article provides a comprehensive introduction to the user behavior modeling paradigm along with highlighting several relevant and recent research works.]]></description>
</item><item>
    <title>Representing Users and Items in Large Language Models based Recommender Systems</title>
    <link>https://blog.reachsumit.com/posts/2023/06/llms-for-recsys-entity-representation/</link>
    <pubDate>Sun, 18 Jun 2023 00:00:00 &#43;0000</pubDate><author>
        <name>Sumit Kumar</name>
    </author><guid>https://blog.reachsumit.com/posts/2023/06/llms-for-recsys-entity-representation/</guid>
    <description><![CDATA[<div class="featured-image">
                <img src="/posts/2023/06/llms-for-recsys-entity-representation/featured-image-preview.webp" referrerpolicy="no-referrer">
            </div>Large Language Models (LLMs) have emerged as viable tools for various recommendation tasks. This article highlights various methods for incorporating users, items, and behavior data into the instructions for LLMs.]]></description>
</item><item>
    <title>Tuning Large Language Models for Recommendation Tasks</title>
    <link>https://blog.reachsumit.com/posts/2023/05/tuning-llm-for-recsys/</link>
    <pubDate>Sun, 21 May 2023 00:00:00 &#43;0000</pubDate><author>
        <name>Sumit Kumar</name>
    </author><guid>https://blog.reachsumit.com/posts/2023/05/tuning-llm-for-recsys/</guid>
    <description><![CDATA[<div class="featured-image">
                <img src="/posts/2023/05/tuning-llm-for-recsys/featured-image-preview.webp" referrerpolicy="no-referrer">
            </div>Instruction-tuning methods enable open-source Large Language Models (LLMs) usage for building highly effective recommender systems on private data. This article highlights the latest research work on this paradigm of using LLMs for recommendation tasks.]]></description>
</item><item>
    <title>ChatGPT-based Recommender Systems</title>
    <link>https://blog.reachsumit.com/posts/2023/05/chatgpt-for-recsys/</link>
    <pubDate>Mon, 15 May 2023 00:00:00 &#43;0000</pubDate><author>
        <name>Sumit Kumar</name>
    </author><guid>https://blog.reachsumit.com/posts/2023/05/chatgpt-for-recsys/</guid>
    <description><![CDATA[<div class="featured-image">
                <img src="/posts/2023/05/chatgpt-for-recsys/featured-image-preview.webp" referrerpolicy="no-referrer">
            </div><p>With its outstanding performance, ChatGPT has become a hot topic of discussion in the NLP community and beyond. This article delves into recent efforts to harness the power of ChatGPT for recommendation tasks.</p>]]></description>
</item><item>
    <title>Mixture-of-Experts based Recommender Systems</title>
    <link>https://blog.reachsumit.com/posts/2023/04/moe-for-recsys/</link>
    <pubDate>Sun, 23 Apr 2023 00:00:00 &#43;0000</pubDate><author>
        <name>Sumit Kumar</name>
    </author><guid>https://blog.reachsumit.com/posts/2023/04/moe-for-recsys/</guid>
    <description><![CDATA[<div class="featured-image">
                <img src="/posts/2023/04/moe-for-recsys/featured-image-preview.webp" referrerpolicy="no-referrer">
            </div><p>The Mixture-of-Experts (MoE) is a classical ensemble learning technique originally proposed by Jacobs et. al<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> in 1991. MoEs have the capability to substantially scale up the model capacity and only introduce small computation overhead. This ability combined with recent innovations in the deep learning domain has led to the wide-scale adoption of MoEs in healthcare, finance, pattern recognition, etc. They have been successfully utilized in large-scale applications such as Large Language Modeling (LLM), Machine Translation, and Recommendations. This article gives an introduction to Mixture-of-Experts and some of the most important enhancements made to the original MoE proposal. Then we look at how MoEs have been adapted to compute recommendations by looking at examples of such systems in production.</p>]]></description>
</item><item>
    <title>Diffusion Modeling based Recommender Systems</title>
    <link>https://blog.reachsumit.com/posts/2023/04/diffusion-for-recsys/</link>
    <pubDate>Mon, 17 Apr 2023 00:00:00 &#43;0000</pubDate><author>
        <name>Sumit Kumar</name>
    </author><guid>https://blog.reachsumit.com/posts/2023/04/diffusion-for-recsys/</guid>
    <description><![CDATA[<div class="featured-image">
                <img src="/posts/2023/04/diffusion-for-recsys/featured-image-preview.webp" referrerpolicy="no-referrer">
            </div>Diffusion Models have exhibited state-of-the-art results in image and audio synthesis domains. A recent line of research has started to adopt Diffusion for recommender systems. This article introduces Diffusion and its relevance to the recommendations domain and also highlights some of the most recent proposals on this novel theme.]]></description>
</item></channel>
</rss>
